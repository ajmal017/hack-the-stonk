{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.6/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr \n",
    "from datetime import date\n",
    "import yfinance as yf \n",
    "yf.pdr_override()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import quandl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_sp = '^GSPC'\n",
    "ticker_gold = 'GC=F'\n",
    "ticker_oil = 'CL=F'\n",
    "ticker_dax = '^GDAXI'\n",
    "ticker_nikkei = '^N225'\n",
    "ticker_ftse = '^FTSE'\n",
    "ticker_shanghai = '000001.SS'\n",
    "\n",
    "auth_tok = \"Nv1rJgRR7u88iz_dg7Y6\"\n",
    "\n",
    "end_date = \"2020-05-1\"\n",
    "start_date = \"1950-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGOLDData ():\n",
    "    # Contains price and volume\n",
    "    data = quandl.get(\"CHRIS/CME_GC1\", trim_start = start_date, trim_end = end_date, authtoken=auth_tok)\n",
    "    data = data[['Last', 'Volume']]\n",
    "    data.columns = [\"GOLD Adj Close\", \"GOLD Volume\"]\n",
    "    return data.dropna()\n",
    "\n",
    "def getSPData():\n",
    "    # Contains price and volume\n",
    "    data = pdr.get_data_yahoo(ticker_sp, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:6]] \n",
    "    data.columns = [\"SP500 Adj Close\",  \"SP500 Volume\"]\n",
    "    return data\n",
    "\n",
    "def getDAXData():\n",
    "    # Contains price and volume\n",
    "    data = pdr.get_data_yahoo(ticker_dax, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:6]]\n",
    "    data.columns = [\"DAX Adj Close\",  \"DAX Volume\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def getOILData():\n",
    "    # Contains price and volume\n",
    "    data = quandl.get(\"CHRIS/CME_CL1\", trim_start = start_date, trim_end = end_date, authtoken=auth_tok)\n",
    "    data = data[[\"Last\", \"Volume\"]]\n",
    "    data.columns=[\"OIL Adj Close\", \"OIL Volume\"]\n",
    "    return data.dropna()\n",
    "\n",
    "\n",
    "def getNIKKEIData():\n",
    "    # Contains only price\n",
    "    data = pdr.get_data_yahoo(ticker_nikkei, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]] \n",
    "    data.columns = [\"NIKKEI Adj Close\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def getFTSEData():\n",
    "    # Contains price and volume\n",
    "    data = pdr.get_data_yahoo(ticker_ftse, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:6]] \n",
    "    data.columns = [\"FTSE Adj Close\",  \"FTSE Volume\"]\n",
    "    return data\n",
    "\n",
    "def getSHANGHAIData():\n",
    "    # Contains only price\n",
    "    data = pdr.get_data_yahoo(ticker_shanghai, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]] \n",
    "    data.columns = [\"SHANGHAI Adj Close\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkData (data):\n",
    "    counter = 0\n",
    "    for index, row in data.iterrows():\n",
    "        for item in row:\n",
    "            if (math.isnan(item)):\n",
    "                counter += 1\n",
    "                break\n",
    "    return counter\n",
    "\n",
    "def normalizeData(data):\n",
    "    for column in data:\n",
    "        maxValue = max(data[column])\n",
    "        data[column] = data[column] / maxValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData():\n",
    "    #allData = [getSPData(), getGOLDData(), getDAXData(), getOILData(), getNIKKEIData(), getSHANGHAIData(), getFTSEData()]\n",
    "    allData = [getSPData()]\n",
    "    mergedData = pd.concat(allData, axis = 1)\n",
    "    print(\"REMOVED: {} DATA POINTS\".format(checkData(mergedData)))\n",
    "    cleanData = mergedData.dropna()\n",
    "    normalizeData(cleanData)\n",
    "    return cleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "REMOVED: 0 DATA POINTS\n",
      "            SP500 Adj Close  SP500 Volume\n",
      "Date                                     \n",
      "1950-01-03         0.004920      0.000110\n",
      "1950-01-04         0.004976      0.000165\n",
      "1950-01-05         0.005000      0.000223\n",
      "1950-01-06         0.005015      0.000175\n",
      "1950-01-09         0.005044      0.000220\n",
      "...                     ...           ...\n",
      "2020-04-24         0.837748      0.469132\n",
      "2020-04-27         0.850075      0.453400\n",
      "2020-04-28         0.845618      0.495179\n",
      "2020-04-29         0.868098      0.577864\n",
      "2020-04-30         0.860101      0.569395\n",
      "\n",
      "[17696 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = combineData()\n",
    "\n",
    "print(data)\n",
    "\n",
    "day_counter = 0\n",
    "\n",
    "# Size of prediction\n",
    "prediction_size = 3\n",
    "\n",
    "# Number of days in the past\n",
    "historical_size = 15\n",
    "\n",
    "# Size of available data.\n",
    "data_size = len(data) - prediction_size - historical_size\n",
    "\n",
    "# Size of data alocated to training\n",
    "training_size = int(0.85*data_size)\n",
    "\n",
    "# Size of data alocated to testing\n",
    "testing_size = data_size - training_size\n",
    "\n",
    "# Number of data elements in a single day\n",
    "daily_data_size = 2 \n",
    "\n",
    "x_train = np.zeros((training_size, historical_size, daily_data_size))\n",
    "y_train = np.zeros((training_size))\n",
    "x_test  = np.zeros((testing_size, historical_size, daily_data_size))\n",
    "y_test  = np.zeros((testing_size))\n",
    "\n",
    "sanity_train = np.zeros((training_size, 3))\n",
    "sanity_test = np.zeros((testing_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% completed\n"
     ]
    }
   ],
   "source": [
    "day_counter = 0\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    if (day_counter == data_size):\n",
    "        print(\"100% completed\")\n",
    "        break\n",
    "\n",
    "    if (day_counter < len(x_train)):\n",
    "        \n",
    "        \n",
    "        for i in range (historical_size):\n",
    "            for j in range (daily_data_size):\n",
    "                x_train[day_counter][i][j] = data.iloc[day_counter + i][j]\n",
    "                \n",
    "        base_value = data.iloc[day_counter + historical_size - 1]['SP500 Adj Close']\n",
    "        future_values = []\n",
    "        for i in range (prediction_size):\n",
    "            future_values += [data.iloc[day_counter + historical_size + i]['SP500 Adj Close']] \n",
    "        average_future = sum(future_values) / len(future_values)\n",
    "        if ((average_future - base_value) > 0):\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = 0\n",
    "            \n",
    "        y_train[day_counter] = delta\n",
    "        \n",
    "        sanity_train[day_counter] = np.array(future_values)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for i in range (historical_size):\n",
    "            for j in range (daily_data_size):\n",
    "                x_test[day_counter - len(x_train)][i][j] = data.iloc[day_counter + i][j]\n",
    "                \n",
    "        base_value = data.iloc[day_counter + historical_size - 1]['SP500 Adj Close']\n",
    "        future_values = []\n",
    "        for i in range (prediction_size):\n",
    "            future_values += [data.iloc[day_counter + historical_size + i]['SP500 Adj Close']] \n",
    "        average_future = sum(future_values) / len(future_values)\n",
    "        if ((average_future - base_value) > 0):\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = 0\n",
    "            \n",
    "        y_test[day_counter - len(y_train)] = delta\n",
    "        \n",
    "        sanity_test[day_counter - len(y_train)] = np.array(future_values)\n",
    "        \n",
    "    day_counter += 1\n",
    "    print(\"{}% completed\".format(int(100 * day_counter/data_size)), end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype('uint8')\n",
    "y_test  = y_test.astype('uint8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance out training data\n",
    "ones = 0\n",
    "zeros = 0\n",
    "for i in y_train:\n",
    "    if (i == 1):\n",
    "        ones += 1\n",
    "    else:\n",
    "        zeros += 1\n",
    "balanced_x_train = np.zeros((2*min(ones,zeros), historical_size, daily_data_size))\n",
    "balanced_y_train = np.zeros((2*min(ones,zeros)))\n",
    "balanced_sanity_train = np.zeros((2*min(ones,zeros), 3))\n",
    "\n",
    "# Insert ones\n",
    "index = 0\n",
    "for i in range (len(x_train)):\n",
    "    if (y_train[i] == 1):\n",
    "        balanced_x_train[index] = x_train[i]\n",
    "        balanced_y_train[index] = y_train[i]\n",
    "        balanced_sanity_train[index] = sanity_train[i]\n",
    "        index += 1\n",
    "        \n",
    "    if (index == min(ones, zeros)):\n",
    "        break\n",
    "        \n",
    "# Insert zeros\n",
    "for i in range (len(x_train)):\n",
    "    if (y_train[i] == 0):\n",
    "        balanced_x_train[index] = x_train[i]\n",
    "        balanced_y_train[index] = y_train[i]\n",
    "        balanced_sanity_train[index] = sanity_train[i]\n",
    "        index += 1\n",
    "        \n",
    "    if (index == len(balanced_x_train)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance out testing data\n",
    "ones = 0\n",
    "zeros = 0\n",
    "for i in y_test:\n",
    "    if (i == 1):\n",
    "        ones += 1\n",
    "    else:\n",
    "        zeros += 1\n",
    "balanced_x_test = np.zeros((2*min(ones,zeros), historical_size, daily_data_size))\n",
    "balanced_y_test = np.zeros((2*min(ones,zeros)))\n",
    "balanced_sanity_test = np.zeros((2*min(ones,zeros), 3))\n",
    "\n",
    "# Insert ones\n",
    "index = 0\n",
    "for i in range (len(x_test)):\n",
    "    if (y_test[i] == 1):\n",
    "        balanced_x_test[index] = x_test[i]\n",
    "        balanced_y_test[index] = y_test[i]\n",
    "        balanced_sanity_test[index] = sanity_test[i]\n",
    "        index += 1\n",
    "        \n",
    "    if (index == min(ones, zeros)):\n",
    "        break\n",
    "        \n",
    "# Insert zeros\n",
    "for i in range (len(x_test)):\n",
    "    if (y_test[i] == 0):\n",
    "        balanced_x_test[index] = x_test[i]\n",
    "        balanced_y_test[index] = y_test[i]\n",
    "        balanced_sanity_test[index] = sanity_test[i]\n",
    "        index += 1\n",
    "        \n",
    "    if (index == len(balanced_x_test)):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114\n",
      "1114\n"
     ]
    }
   ],
   "source": [
    "ones = 0\n",
    "zeros = 0\n",
    "for i in balanced_y_test:\n",
    "    if (i == 1):\n",
    "        ones += 1\n",
    "    else:\n",
    "        zeros += 1\n",
    "        \n",
    "print(ones)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/juan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \"\"\"\n",
      "/home/juan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  \n",
      "/home/juan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/juan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if sys.path[0] == '':\n",
      "/home/juan/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle training data\n",
    "randomize_training = np.arange(len(balanced_x_train))\n",
    "np.random.shuffle(randomize_training)\n",
    "balanced_x_train = balanced_x_train[[randomize_training]]\n",
    "balanced_y_train = balanced_y_train[[randomize_training]]\n",
    "balanced_sanity_train = balanced_sanity_train[[randomize_training]]\n",
    "\n",
    "# Shuffle testing data\n",
    "randomize_testing = np.arange(len(balanced_x_test))\n",
    "np.random.shuffle(randomize_testing)\n",
    "balanced_x_test = balanced_x_test[[randomize_testing]]\n",
    "balanced_y_test = balanced_y_test[[randomize_testing]]\n",
    "balanced_sanity_test = balanced_sanity_test[[randomize_testing]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_y_train = balanced_y_train.astype('uint8')\n",
    "balanced_y_test  = balanced_y_test.astype('uint8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
