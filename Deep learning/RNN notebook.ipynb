{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr \n",
    "from datetime import date\n",
    "import yfinance as yf \n",
    "yf.pdr_override()\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "import quandl\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_sp = '^GSPC'\n",
    "ticker_gold = 'GC=F'\n",
    "ticker_oil = 'CL=F'\n",
    "ticker_dax = '^GDAXI'\n",
    "ticker_nikkei = '^N225'\n",
    "ticker_ftse = '^FTSE'\n",
    "ticker_shanghai = '000001.SS'\n",
    "\n",
    "auth_tok = \"Nv1rJgRR7u88iz_dg7Y6\"\n",
    "\n",
    "end_date = \"2020-09-1\"\n",
    "start_date = \"1970-01-02\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGOLDData ():\n",
    "    # Contains only price from 1975 onwards\n",
    "    data = quandl.get(\"CHRIS/CME_GC1\", trim_start = start_date, trim_end = end_date, authtoken=auth_tok)\n",
    "    data = data[['Last']]\n",
    "    data.columns = [\"GOLD Adj Close\"]\n",
    "    return data\n",
    "\n",
    "def getSPData():\n",
    "    # Contains price from 1970 onwards\n",
    "    data = pdr.get_data_yahoo(ticker_sp, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]] \n",
    "    data.columns = [\"SP500 Adj Close\"]\n",
    "    return data\n",
    "\n",
    "def getDAXData():\n",
    "    # Contains price from 1988 onwards\n",
    "    data = pdr.get_data_yahoo(ticker_dax, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]]\n",
    "    data.columns = [\"DAX Adj Close\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def getOILData():\n",
    "    # Contains only price FROM 1984 onwards\n",
    "    data = quandl.get(\"CHRIS/CME_CL1\", trim_start = start_date, trim_end = end_date, authtoken=auth_tok)\n",
    "    data = data[[\"Last\"]]\n",
    "    data.columns=[\"OIL Adj Close\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def getNIKKEIData():\n",
    "    # Contains only price from 1970 onwards\n",
    "    data = pdr.get_data_yahoo(ticker_nikkei, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]] \n",
    "    data.columns = [\"NIKKEI Adj Close\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def getFTSEData():\n",
    "    # Contains price from 1984 onwards\n",
    "    data = pdr.get_data_yahoo(ticker_ftse, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]] \n",
    "    data.columns = [\"FTSE Adj Close\"]\n",
    "    return data\n",
    "\n",
    "def getSHANGHAIData():\n",
    "    # Contains only price from 1997\n",
    "    data = pdr.get_data_yahoo(ticker_shanghai, start=start_date, end=end_date)\n",
    "    data = data[data.columns[4:5]] \n",
    "    data.columns = [\"SHANGHAI Adj Close\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData():\n",
    "    allData = [getSPData(), getDAXData(), getFTSEData(), getGOLDData(), getOILData()]\n",
    "    mergedData = pd.concat(allData, axis = 1)\n",
    "    cleanData = mergedData.dropna()\n",
    "    return cleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "size of training data: 6723\n",
      "size of testing data: 1187\n"
     ]
    }
   ],
   "source": [
    "data = combineData()\n",
    "\n",
    "FUTURE_TO_PREDICT = 1 # Number of days into the future we want to predict\n",
    "\n",
    "data['Future'] = data['SP500 Adj Close'].shift(-FUTURE_TO_PREDICT)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "def buy_or_sell (current, future):\n",
    "    if (future > current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data['Target'] = list(map(buy_or_sell, data['SP500 Adj Close'], data['Future']))\n",
    "\n",
    "NUMBER_OF_DATA_POINTS = len(data)\n",
    "SIZE_TRAINING = int(NUMBER_OF_DATA_POINTS * 0.85)\n",
    "SIZE_TESTING  = NUMBER_OF_DATA_POINTS - SIZE_TRAINING\n",
    "print(\"size of training data: {}\".format(SIZE_TRAINING))\n",
    "print(\"size of testing data: {}\".format(SIZE_TESTING))\n",
    "\n",
    "data_training = data[:SIZE_TRAINING]\n",
    "data_testing  = data[SIZE_TRAINING:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            SP500 Adj Close  DAX Adj Close  FTSE Adj Close  GOLD Adj Close  \\\n",
      "Date                                                                         \n",
      "1987-12-30       247.860001    1005.190002     1759.800049           485.5   \n",
      "1988-01-04       255.940002     956.489990     1713.900024           480.5   \n",
      "1988-01-05       258.630005     996.099976     1789.599976           483.2   \n",
      "1988-01-06       258.890015    1006.010010     1787.099976           485.3   \n",
      "1988-01-07       261.070007    1014.469971     1787.199951           483.1   \n",
      "...                     ...            ...             ...             ...   \n",
      "2015-08-25      1867.609985   10128.120117     6081.299805          1139.7   \n",
      "2015-08-26      1940.510010    9997.429688     5979.200195          1124.5   \n",
      "2015-08-27      1987.660034   10315.620117     6192.000000          1123.4   \n",
      "2015-08-28      1988.869995   10298.530273     6247.899902          1132.8   \n",
      "2015-09-01      1913.849976   10015.570312     6058.500000          1139.0   \n",
      "\n",
      "            OIL Adj Close       Future  Target  \n",
      "Date                                            \n",
      "1987-12-30          16.89   255.940002       1  \n",
      "1988-01-04          17.69   258.630005       1  \n",
      "1988-01-05          17.85   258.890015       1  \n",
      "1988-01-06          17.82   261.070007       1  \n",
      "1988-01-07          17.39   243.399994       0  \n",
      "...                   ...          ...     ...  \n",
      "2015-08-25          39.64  1940.510010       1  \n",
      "2015-08-26          38.88  1987.660034       1  \n",
      "2015-08-27          42.78  1988.869995       1  \n",
      "2015-08-28          45.33  1913.849976       0  \n",
      "2015-09-01          44.19  1948.859985       1  \n",
      "\n",
      "[6723 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data.drop(\"Future\", axis = 1, inplace = True)  # Drop the future column so that the NN doesn't have access to the future\n",
    "    \n",
    "    for column in data.columns:  # Normalize the columns\n",
    "        if column != \"Target\":   # We only want to normalize the other columns\n",
    "            data[column] = data[column].pct_change()   # Normalization by percent change\n",
    "            data.dropna(inplace = True)\n",
    "            data[column] = preprocessing.scale(data[column].values)    # First testing without scaling\n",
    "    \n",
    "    data.dropna(inplace = True)\n",
    "\n",
    "    sequential_data = []\n",
    "    sequence_length = 15 # Number of days into the past we are using to make a prediction\n",
    "    \n",
    "    for day in range (len(data)-sequence_length+1):\n",
    "        \n",
    "        sequence = []\n",
    "        \n",
    "        for future_day in range (sequence_length):\n",
    "            sequence.append(data.iloc[day + future_day][:-1])\n",
    "        \n",
    "        buy_or_sell = data.iloc[day + sequence_length - 1][-1]\n",
    "        \n",
    "        sequential_data.append([sequence, buy_or_sell])\n",
    "    \n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buy_sequences  = []\n",
    "    sell_sequences = []\n",
    "    \n",
    "    for sequence, target in sequential_data:\n",
    "        if target == 1:\n",
    "            buy_sequences.append([sequence, target])\n",
    "        elif target == 0:\n",
    "            sell_sequences.append([sequence, target])\n",
    "            \n",
    "    print(\"{} buys\".format(len(buy_sequences)))\n",
    "    print(\"{} sells\".format(len(sell_sequences)))\n",
    "    \n",
    "    random.shuffle(buy_sequences)\n",
    "    random.shuffle(sell_sequences)\n",
    "    \n",
    "    max_size = min(len(buy_sequences), len(sell_sequences))\n",
    "    \n",
    "    print(\"reduced to {} buys and sells\".format(max_size))\n",
    "    \n",
    "    buy_sequences  = buy_sequences[:max_size]\n",
    "    sell_sequences = sell_sequences[:max_size]\n",
    "    \n",
    "    sequential_data = buy_sequences + sell_sequences\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for sequence, target in sequential_data:\n",
    "        x.append(sequence)\n",
    "        y.append(target)\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3597 buys\n",
      "3107 sells\n",
      "reduced to 3107 buys and sells\n",
      "651 buys\n",
      "517 sells\n",
      "reduced to 517 buys and sells\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = process_data(data_training)\n",
    "x_test, y_test   = process_data(data_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "LSTM_LAYERS = 3\n",
    "LSTM_REPRESENTATION = 32\n",
    "DENSE_REPRESENTATION = 16\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "model.add(LSTM(LSTM_REPRESENTATION, activation = 'relu', input_shape = (x_train.shape[1:]), return_sequences = True))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(LSTM_REPRESENTATION, return_sequences = True))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(LSTM_REPRESENTATION))\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(DENSE_REPRESENTATION, activation = 'relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=LEARNING_RATE, decay = 1e-6)\n",
    "\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = opt,\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs\\LSTM-{}-DENSE-{}-LAYERS-{}-DROPOUT-{}-LR-{}-BS-{}-MK-10\".format(LSTM_REPRESENTATION, DENSE_REPRESENTATION, LSTM_LAYERS, DROPOUT, LEARNING_RATE, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6214 samples, validate on 1034 samples\n",
      "Epoch 1/1200\n",
      "6214/6214 [==============================] - 13s 2ms/step - loss: 0.8532 - acc: 0.5023 - val_loss: 0.6966 - val_acc: 0.4932\n",
      "Epoch 2/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8358 - acc: 0.5126 - val_loss: 0.7189 - val_acc: 0.4855\n",
      "Epoch 3/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8277 - acc: 0.5085 - val_loss: 0.7408 - val_acc: 0.4874\n",
      "Epoch 4/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8265 - acc: 0.5016 - val_loss: 0.7442 - val_acc: 0.4797\n",
      "Epoch 5/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8076 - acc: 0.5076 - val_loss: 0.7404 - val_acc: 0.4894\n",
      "Epoch 6/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8216 - acc: 0.4931 - val_loss: 0.7374 - val_acc: 0.4913\n",
      "Epoch 7/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8009 - acc: 0.5101 - val_loss: 0.7329 - val_acc: 0.4942\n",
      "Epoch 8/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.8049 - acc: 0.4960 - val_loss: 0.7306 - val_acc: 0.4932\n",
      "Epoch 9/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7946 - acc: 0.5003 - val_loss: 0.7267 - val_acc: 0.5000\n",
      "Epoch 10/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7937 - acc: 0.5105 - val_loss: 0.7251 - val_acc: 0.4942\n",
      "Epoch 11/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7972 - acc: 0.4977 - val_loss: 0.7237 - val_acc: 0.4942\n",
      "Epoch 12/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7812 - acc: 0.5105 - val_loss: 0.7223 - val_acc: 0.4961\n",
      "Epoch 13/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7893 - acc: 0.5024 - val_loss: 0.7213 - val_acc: 0.4961\n",
      "Epoch 14/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7757 - acc: 0.5108 - val_loss: 0.7204 - val_acc: 0.5010\n",
      "Epoch 15/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7798 - acc: 0.5132 - val_loss: 0.7191 - val_acc: 0.5019\n",
      "Epoch 16/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7734 - acc: 0.5105 - val_loss: 0.7175 - val_acc: 0.4961\n",
      "Epoch 17/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7797 - acc: 0.5019 - val_loss: 0.7172 - val_acc: 0.4981\n",
      "Epoch 18/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7750 - acc: 0.5008 - val_loss: 0.7164 - val_acc: 0.4932\n",
      "Epoch 19/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7798 - acc: 0.5010 - val_loss: 0.7156 - val_acc: 0.5000\n",
      "Epoch 20/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7753 - acc: 0.4974 - val_loss: 0.7150 - val_acc: 0.4952\n",
      "Epoch 21/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7704 - acc: 0.5021 - val_loss: 0.7145 - val_acc: 0.4971\n",
      "Epoch 22/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7683 - acc: 0.5097 - val_loss: 0.7142 - val_acc: 0.4923\n",
      "Epoch 23/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7690 - acc: 0.5045 - val_loss: 0.7134 - val_acc: 0.4981\n",
      "Epoch 24/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7636 - acc: 0.5050 - val_loss: 0.7128 - val_acc: 0.4961\n",
      "Epoch 25/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7678 - acc: 0.4929 - val_loss: 0.7119 - val_acc: 0.4903\n",
      "Epoch 26/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7632 - acc: 0.5016 - val_loss: 0.7120 - val_acc: 0.4942\n",
      "Epoch 27/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7673 - acc: 0.4998 - val_loss: 0.7114 - val_acc: 0.4913\n",
      "Epoch 28/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7592 - acc: 0.5090 - val_loss: 0.7113 - val_acc: 0.4913\n",
      "Epoch 29/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7640 - acc: 0.5061 - val_loss: 0.7109 - val_acc: 0.4981\n",
      "Epoch 30/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7593 - acc: 0.4998 - val_loss: 0.7101 - val_acc: 0.4990\n",
      "Epoch 31/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7467 - acc: 0.5140 - val_loss: 0.7102 - val_acc: 0.4971\n",
      "Epoch 32/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7537 - acc: 0.5055 - val_loss: 0.7098 - val_acc: 0.5019\n",
      "Epoch 33/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7490 - acc: 0.5098 - val_loss: 0.7097 - val_acc: 0.5048\n",
      "Epoch 34/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7599 - acc: 0.4973 - val_loss: 0.7100 - val_acc: 0.4990\n",
      "Epoch 35/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7512 - acc: 0.4997 - val_loss: 0.7098 - val_acc: 0.5019\n",
      "Epoch 36/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7454 - acc: 0.5163 - val_loss: 0.7090 - val_acc: 0.5019\n",
      "Epoch 37/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7519 - acc: 0.4974 - val_loss: 0.7086 - val_acc: 0.5019\n",
      "Epoch 38/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7483 - acc: 0.5114 - val_loss: 0.7085 - val_acc: 0.5019\n",
      "Epoch 39/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7447 - acc: 0.5069 - val_loss: 0.7084 - val_acc: 0.5048\n",
      "Epoch 40/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7456 - acc: 0.5111 - val_loss: 0.7081 - val_acc: 0.5039\n",
      "Epoch 41/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7393 - acc: 0.5090 - val_loss: 0.7077 - val_acc: 0.5019\n",
      "Epoch 42/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7559 - acc: 0.4879 - val_loss: 0.7077 - val_acc: 0.5000\n",
      "Epoch 43/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7418 - acc: 0.5051 - val_loss: 0.7072 - val_acc: 0.4990\n",
      "Epoch 44/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7378 - acc: 0.5129 - val_loss: 0.7073 - val_acc: 0.4952\n",
      "Epoch 45/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7381 - acc: 0.5045 - val_loss: 0.7073 - val_acc: 0.4981\n",
      "Epoch 46/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7386 - acc: 0.5090 - val_loss: 0.7073 - val_acc: 0.4903\n",
      "Epoch 47/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7402 - acc: 0.5058 - val_loss: 0.7072 - val_acc: 0.4884\n",
      "Epoch 48/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7294 - acc: 0.5154 - val_loss: 0.7065 - val_acc: 0.4884\n",
      "Epoch 49/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7388 - acc: 0.5016 - val_loss: 0.7064 - val_acc: 0.4884\n",
      "Epoch 50/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7371 - acc: 0.5085 - val_loss: 0.7062 - val_acc: 0.4865\n",
      "Epoch 51/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7338 - acc: 0.5185 - val_loss: 0.7058 - val_acc: 0.4932\n",
      "Epoch 52/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7274 - acc: 0.5134 - val_loss: 0.7058 - val_acc: 0.4884\n",
      "Epoch 53/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7406 - acc: 0.4994 - val_loss: 0.7061 - val_acc: 0.4903\n",
      "Epoch 54/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7424 - acc: 0.4981 - val_loss: 0.7058 - val_acc: 0.4923\n",
      "Epoch 55/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7290 - acc: 0.5100 - val_loss: 0.7054 - val_acc: 0.4884\n",
      "Epoch 56/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7352 - acc: 0.5093 - val_loss: 0.7051 - val_acc: 0.5000\n",
      "Epoch 57/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7289 - acc: 0.5171 - val_loss: 0.7050 - val_acc: 0.4971\n",
      "Epoch 58/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7273 - acc: 0.5151 - val_loss: 0.7050 - val_acc: 0.4932\n",
      "Epoch 59/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7300 - acc: 0.5108 - val_loss: 0.7045 - val_acc: 0.4981\n",
      "Epoch 60/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7330 - acc: 0.4973 - val_loss: 0.7047 - val_acc: 0.4981\n",
      "Epoch 61/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7313 - acc: 0.5106 - val_loss: 0.7046 - val_acc: 0.4990\n",
      "Epoch 62/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7279 - acc: 0.5100 - val_loss: 0.7046 - val_acc: 0.5019\n",
      "Epoch 63/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7275 - acc: 0.5010 - val_loss: 0.7044 - val_acc: 0.5039\n",
      "Epoch 64/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7273 - acc: 0.5074 - val_loss: 0.7042 - val_acc: 0.5010\n",
      "Epoch 65/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7304 - acc: 0.4987 - val_loss: 0.7041 - val_acc: 0.4990\n",
      "Epoch 66/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7280 - acc: 0.5031 - val_loss: 0.7039 - val_acc: 0.5010\n",
      "Epoch 67/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7277 - acc: 0.5089 - val_loss: 0.7038 - val_acc: 0.4961\n",
      "Epoch 68/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7282 - acc: 0.5039 - val_loss: 0.7037 - val_acc: 0.4971\n",
      "Epoch 69/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7317 - acc: 0.4974 - val_loss: 0.7034 - val_acc: 0.5019\n",
      "Epoch 70/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7264 - acc: 0.5032 - val_loss: 0.7032 - val_acc: 0.4932\n",
      "Epoch 71/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7253 - acc: 0.5101 - val_loss: 0.7033 - val_acc: 0.4961\n",
      "Epoch 72/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7228 - acc: 0.5126 - val_loss: 0.7032 - val_acc: 0.5019\n",
      "Epoch 73/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7186 - acc: 0.5206 - val_loss: 0.7034 - val_acc: 0.5039\n",
      "Epoch 74/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7219 - acc: 0.5047 - val_loss: 0.7031 - val_acc: 0.5058\n",
      "Epoch 75/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7231 - acc: 0.5109 - val_loss: 0.7030 - val_acc: 0.4990\n",
      "Epoch 76/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7190 - acc: 0.5095 - val_loss: 0.7028 - val_acc: 0.5097\n",
      "Epoch 77/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7216 - acc: 0.5121 - val_loss: 0.7029 - val_acc: 0.5010\n",
      "Epoch 78/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7200 - acc: 0.5113 - val_loss: 0.7029 - val_acc: 0.5029\n",
      "Epoch 79/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7170 - acc: 0.5171 - val_loss: 0.7029 - val_acc: 0.5039\n",
      "Epoch 80/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7282 - acc: 0.4992 - val_loss: 0.7027 - val_acc: 0.5048\n",
      "Epoch 81/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7263 - acc: 0.5011 - val_loss: 0.7022 - val_acc: 0.4990\n",
      "Epoch 82/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7230 - acc: 0.5090 - val_loss: 0.7024 - val_acc: 0.5106\n",
      "Epoch 83/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7166 - acc: 0.5051 - val_loss: 0.7025 - val_acc: 0.5029\n",
      "Epoch 84/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7157 - acc: 0.5084 - val_loss: 0.7023 - val_acc: 0.5087\n",
      "Epoch 85/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7157 - acc: 0.5180 - val_loss: 0.7025 - val_acc: 0.5068\n",
      "Epoch 86/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7206 - acc: 0.5011 - val_loss: 0.7021 - val_acc: 0.5000\n",
      "Epoch 87/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7206 - acc: 0.5056 - val_loss: 0.7021 - val_acc: 0.5058\n",
      "Epoch 88/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7074 - acc: 0.5246 - val_loss: 0.7015 - val_acc: 0.5010\n",
      "Epoch 89/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7214 - acc: 0.5047 - val_loss: 0.7016 - val_acc: 0.5039\n",
      "Epoch 90/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7197 - acc: 0.5026 - val_loss: 0.7017 - val_acc: 0.5068\n",
      "Epoch 91/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7153 - acc: 0.5116 - val_loss: 0.7017 - val_acc: 0.5097\n",
      "Epoch 92/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7141 - acc: 0.5154 - val_loss: 0.7010 - val_acc: 0.5039\n",
      "Epoch 93/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7169 - acc: 0.5092 - val_loss: 0.7014 - val_acc: 0.5106\n",
      "Epoch 94/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7124 - acc: 0.5103 - val_loss: 0.7014 - val_acc: 0.5077\n",
      "Epoch 95/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7112 - acc: 0.5224 - val_loss: 0.7010 - val_acc: 0.5077\n",
      "Epoch 96/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7170 - acc: 0.5077 - val_loss: 0.7011 - val_acc: 0.5126\n",
      "Epoch 97/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7209 - acc: 0.4992 - val_loss: 0.7009 - val_acc: 0.5126\n",
      "Epoch 98/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7119 - acc: 0.5095 - val_loss: 0.7008 - val_acc: 0.5126\n",
      "Epoch 99/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7151 - acc: 0.5034 - val_loss: 0.7007 - val_acc: 0.5087\n",
      "Epoch 100/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7115 - acc: 0.5077 - val_loss: 0.7007 - val_acc: 0.5097\n",
      "Epoch 101/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7149 - acc: 0.5053 - val_loss: 0.7004 - val_acc: 0.5106\n",
      "Epoch 102/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7124 - acc: 0.5146 - val_loss: 0.7007 - val_acc: 0.5068\n",
      "Epoch 103/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7142 - acc: 0.5089 - val_loss: 0.7007 - val_acc: 0.5116\n",
      "Epoch 104/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7115 - acc: 0.5190 - val_loss: 0.7002 - val_acc: 0.5097\n",
      "Epoch 105/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7127 - acc: 0.5064 - val_loss: 0.7002 - val_acc: 0.5106\n",
      "Epoch 106/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7097 - acc: 0.5114 - val_loss: 0.7000 - val_acc: 0.5126\n",
      "Epoch 107/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7136 - acc: 0.5074 - val_loss: 0.7000 - val_acc: 0.5077\n",
      "Epoch 108/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7072 - acc: 0.5192 - val_loss: 0.6999 - val_acc: 0.5135\n",
      "Epoch 109/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7126 - acc: 0.5058 - val_loss: 0.7002 - val_acc: 0.5106\n",
      "Epoch 110/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7077 - acc: 0.5232 - val_loss: 0.6999 - val_acc: 0.5097\n",
      "Epoch 111/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7151 - acc: 0.5051 - val_loss: 0.6998 - val_acc: 0.5068\n",
      "Epoch 112/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7108 - acc: 0.5063 - val_loss: 0.6999 - val_acc: 0.5116\n",
      "Epoch 113/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7153 - acc: 0.5048 - val_loss: 0.6997 - val_acc: 0.5126\n",
      "Epoch 114/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7152 - acc: 0.4986 - val_loss: 0.6998 - val_acc: 0.5048\n",
      "Epoch 115/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7108 - acc: 0.5193 - val_loss: 0.6995 - val_acc: 0.5058\n",
      "Epoch 116/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7066 - acc: 0.5119 - val_loss: 0.6996 - val_acc: 0.5106\n",
      "Epoch 117/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7072 - acc: 0.5129 - val_loss: 0.6997 - val_acc: 0.5106\n",
      "Epoch 118/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7105 - acc: 0.5082 - val_loss: 0.6993 - val_acc: 0.5077\n",
      "Epoch 119/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7101 - acc: 0.5097 - val_loss: 0.6990 - val_acc: 0.5097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7085 - acc: 0.5106 - val_loss: 0.6993 - val_acc: 0.5126\n",
      "Epoch 121/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7075 - acc: 0.5137 - val_loss: 0.6989 - val_acc: 0.5164\n",
      "Epoch 122/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7060 - acc: 0.5200 - val_loss: 0.6991 - val_acc: 0.5097\n",
      "Epoch 123/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7107 - acc: 0.5072 - val_loss: 0.6990 - val_acc: 0.5106\n",
      "Epoch 124/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7066 - acc: 0.5235 - val_loss: 0.6991 - val_acc: 0.5116\n",
      "Epoch 125/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7044 - acc: 0.5241 - val_loss: 0.6989 - val_acc: 0.5126\n",
      "Epoch 126/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7048 - acc: 0.5183 - val_loss: 0.6990 - val_acc: 0.5058\n",
      "Epoch 127/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7083 - acc: 0.5055 - val_loss: 0.6988 - val_acc: 0.5116\n",
      "Epoch 128/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7138 - acc: 0.4974 - val_loss: 0.6987 - val_acc: 0.5126\n",
      "Epoch 129/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7072 - acc: 0.5138 - val_loss: 0.6988 - val_acc: 0.5087\n",
      "Epoch 130/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7044 - acc: 0.5179 - val_loss: 0.6987 - val_acc: 0.5010\n",
      "Epoch 131/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7068 - acc: 0.5092 - val_loss: 0.6986 - val_acc: 0.5019\n",
      "Epoch 132/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7085 - acc: 0.5146 - val_loss: 0.6983 - val_acc: 0.5087\n",
      "Epoch 133/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7040 - acc: 0.5175 - val_loss: 0.6983 - val_acc: 0.5058\n",
      "Epoch 134/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7060 - acc: 0.5071 - val_loss: 0.6980 - val_acc: 0.5048\n",
      "Epoch 135/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7037 - acc: 0.5097 - val_loss: 0.6982 - val_acc: 0.5058\n",
      "Epoch 136/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7028 - acc: 0.5224 - val_loss: 0.6982 - val_acc: 0.5068\n",
      "Epoch 137/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7074 - acc: 0.5031 - val_loss: 0.6981 - val_acc: 0.5097\n",
      "Epoch 138/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7031 - acc: 0.5142 - val_loss: 0.6981 - val_acc: 0.5058\n",
      "Epoch 139/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7091 - acc: 0.5014 - val_loss: 0.6981 - val_acc: 0.5048\n",
      "Epoch 140/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7042 - acc: 0.5143 - val_loss: 0.6980 - val_acc: 0.5058\n",
      "Epoch 141/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7031 - acc: 0.5171 - val_loss: 0.6979 - val_acc: 0.5077\n",
      "Epoch 142/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7044 - acc: 0.5164 - val_loss: 0.6980 - val_acc: 0.5087\n",
      "Epoch 143/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7030 - acc: 0.5106 - val_loss: 0.6979 - val_acc: 0.5010\n",
      "Epoch 144/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7078 - acc: 0.5068 - val_loss: 0.6975 - val_acc: 0.5068\n",
      "Epoch 145/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7018 - acc: 0.5204 - val_loss: 0.6978 - val_acc: 0.5010\n",
      "Epoch 146/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7070 - acc: 0.5080 - val_loss: 0.6975 - val_acc: 0.5048\n",
      "Epoch 147/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7013 - acc: 0.5233 - val_loss: 0.6976 - val_acc: 0.5019\n",
      "Epoch 148/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6994 - acc: 0.5301 - val_loss: 0.6973 - val_acc: 0.5068\n",
      "Epoch 149/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7042 - acc: 0.5127 - val_loss: 0.6976 - val_acc: 0.5000\n",
      "Epoch 150/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6979 - acc: 0.5294 - val_loss: 0.6976 - val_acc: 0.5058\n",
      "Epoch 151/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7043 - acc: 0.5175 - val_loss: 0.6973 - val_acc: 0.5058\n",
      "Epoch 152/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7025 - acc: 0.5158 - val_loss: 0.6975 - val_acc: 0.4971\n",
      "Epoch 153/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7007 - acc: 0.5243 - val_loss: 0.6974 - val_acc: 0.5029\n",
      "Epoch 154/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7019 - acc: 0.5212 - val_loss: 0.6972 - val_acc: 0.4971\n",
      "Epoch 155/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6998 - acc: 0.5212 - val_loss: 0.6971 - val_acc: 0.4961\n",
      "Epoch 156/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7079 - acc: 0.5076 - val_loss: 0.6976 - val_acc: 0.4923\n",
      "Epoch 157/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7015 - acc: 0.5164 - val_loss: 0.6975 - val_acc: 0.4894\n",
      "Epoch 158/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7035 - acc: 0.5174 - val_loss: 0.6974 - val_acc: 0.4971\n",
      "Epoch 159/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7011 - acc: 0.5201 - val_loss: 0.6976 - val_acc: 0.4874\n",
      "Epoch 160/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7034 - acc: 0.5180 - val_loss: 0.6974 - val_acc: 0.4942\n",
      "Epoch 161/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7019 - acc: 0.5156 - val_loss: 0.6973 - val_acc: 0.4903\n",
      "Epoch 162/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6974 - acc: 0.5277 - val_loss: 0.6972 - val_acc: 0.4913\n",
      "Epoch 163/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7018 - acc: 0.5232 - val_loss: 0.6974 - val_acc: 0.4923\n",
      "Epoch 164/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7070 - acc: 0.5048 - val_loss: 0.6973 - val_acc: 0.4913\n",
      "Epoch 165/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7009 - acc: 0.5204 - val_loss: 0.6973 - val_acc: 0.4942\n",
      "Epoch 166/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7025 - acc: 0.5143 - val_loss: 0.6974 - val_acc: 0.4932\n",
      "Epoch 167/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7034 - acc: 0.5035 - val_loss: 0.6973 - val_acc: 0.4961\n",
      "Epoch 168/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7039 - acc: 0.5148 - val_loss: 0.6974 - val_acc: 0.4932\n",
      "Epoch 169/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7014 - acc: 0.5116 - val_loss: 0.6974 - val_acc: 0.4884\n",
      "Epoch 170/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6978 - acc: 0.5243 - val_loss: 0.6973 - val_acc: 0.4865\n",
      "Epoch 171/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7046 - acc: 0.5105 - val_loss: 0.6972 - val_acc: 0.4874\n",
      "Epoch 172/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6953 - acc: 0.5275 - val_loss: 0.6970 - val_acc: 0.4913\n",
      "Epoch 173/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6994 - acc: 0.5161 - val_loss: 0.6968 - val_acc: 0.4894\n",
      "Epoch 174/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6998 - acc: 0.5154 - val_loss: 0.6968 - val_acc: 0.4845\n",
      "Epoch 175/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7018 - acc: 0.5159 - val_loss: 0.6968 - val_acc: 0.4903\n",
      "Epoch 176/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6980 - acc: 0.5175 - val_loss: 0.6965 - val_acc: 0.4874\n",
      "Epoch 177/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7041 - acc: 0.5060 - val_loss: 0.6967 - val_acc: 0.4855\n",
      "Epoch 178/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7011 - acc: 0.5140 - val_loss: 0.6966 - val_acc: 0.4865\n",
      "Epoch 179/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7012 - acc: 0.5200 - val_loss: 0.6963 - val_acc: 0.4884\n",
      "Epoch 180/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6979 - acc: 0.5204 - val_loss: 0.6963 - val_acc: 0.4913\n",
      "Epoch 181/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6996 - acc: 0.5193 - val_loss: 0.6965 - val_acc: 0.4845\n",
      "Epoch 182/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6989 - acc: 0.5227 - val_loss: 0.6964 - val_acc: 0.4855\n",
      "Epoch 183/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7007 - acc: 0.5172 - val_loss: 0.6962 - val_acc: 0.4923\n",
      "Epoch 184/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7004 - acc: 0.5214 - val_loss: 0.6961 - val_acc: 0.4961\n",
      "Epoch 185/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.7025 - acc: 0.5164 - val_loss: 0.6961 - val_acc: 0.4932\n",
      "Epoch 186/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7028 - acc: 0.5122 - val_loss: 0.6962 - val_acc: 0.4971\n",
      "Epoch 187/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7002 - acc: 0.5095 - val_loss: 0.6961 - val_acc: 0.4971\n",
      "Epoch 188/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7022 - acc: 0.5050 - val_loss: 0.6961 - val_acc: 0.4971\n",
      "Epoch 189/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6989 - acc: 0.5232 - val_loss: 0.6960 - val_acc: 0.4990\n",
      "Epoch 190/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6984 - acc: 0.5140 - val_loss: 0.6961 - val_acc: 0.4981\n",
      "Epoch 191/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7003 - acc: 0.5175 - val_loss: 0.6958 - val_acc: 0.4952\n",
      "Epoch 192/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7012 - acc: 0.5090 - val_loss: 0.6960 - val_acc: 0.5010\n",
      "Epoch 193/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7039 - acc: 0.5064 - val_loss: 0.6960 - val_acc: 0.5010\n",
      "Epoch 194/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6995 - acc: 0.5111 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 195/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6969 - acc: 0.5209 - val_loss: 0.6960 - val_acc: 0.5077\n",
      "Epoch 196/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6993 - acc: 0.5132 - val_loss: 0.6958 - val_acc: 0.5019\n",
      "Epoch 197/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7012 - acc: 0.5193 - val_loss: 0.6960 - val_acc: 0.5000\n",
      "Epoch 198/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6997 - acc: 0.5171 - val_loss: 0.6958 - val_acc: 0.5010\n",
      "Epoch 199/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7001 - acc: 0.5142 - val_loss: 0.6956 - val_acc: 0.5019\n",
      "Epoch 200/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6987 - acc: 0.5137 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 201/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6994 - acc: 0.5132 - val_loss: 0.6954 - val_acc: 0.5019\n",
      "Epoch 202/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6997 - acc: 0.5113 - val_loss: 0.6955 - val_acc: 0.4971\n",
      "Epoch 203/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6981 - acc: 0.5135 - val_loss: 0.6954 - val_acc: 0.4961\n",
      "Epoch 204/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6976 - acc: 0.5222 - val_loss: 0.6954 - val_acc: 0.4932\n",
      "Epoch 205/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7025 - acc: 0.5089 - val_loss: 0.6953 - val_acc: 0.4903\n",
      "Epoch 206/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6991 - acc: 0.5085 - val_loss: 0.6953 - val_acc: 0.4894\n",
      "Epoch 207/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6978 - acc: 0.5180 - val_loss: 0.6953 - val_acc: 0.5000\n",
      "Epoch 208/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.7012 - acc: 0.5019 - val_loss: 0.6951 - val_acc: 0.5077\n",
      "Epoch 209/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6982 - acc: 0.5222 - val_loss: 0.6949 - val_acc: 0.5029\n",
      "Epoch 210/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6978 - acc: 0.5148 - val_loss: 0.6951 - val_acc: 0.4971\n",
      "Epoch 211/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6986 - acc: 0.5090 - val_loss: 0.6950 - val_acc: 0.4952\n",
      "Epoch 212/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6966 - acc: 0.5233 - val_loss: 0.6949 - val_acc: 0.4971\n",
      "Epoch 213/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6985 - acc: 0.5146 - val_loss: 0.6950 - val_acc: 0.5077\n",
      "Epoch 214/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6967 - acc: 0.5233 - val_loss: 0.6949 - val_acc: 0.5087\n",
      "Epoch 215/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6978 - acc: 0.5135 - val_loss: 0.6947 - val_acc: 0.5039\n",
      "Epoch 216/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6973 - acc: 0.5179 - val_loss: 0.6947 - val_acc: 0.4981\n",
      "Epoch 217/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6957 - acc: 0.5301 - val_loss: 0.6948 - val_acc: 0.4961\n",
      "Epoch 218/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6961 - acc: 0.5248 - val_loss: 0.6947 - val_acc: 0.5068\n",
      "Epoch 219/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6955 - acc: 0.5182 - val_loss: 0.6946 - val_acc: 0.5019\n",
      "Epoch 220/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6964 - acc: 0.5238 - val_loss: 0.6947 - val_acc: 0.5019\n",
      "Epoch 221/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6967 - acc: 0.5220 - val_loss: 0.6945 - val_acc: 0.5019\n",
      "Epoch 222/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6980 - acc: 0.5079 - val_loss: 0.6945 - val_acc: 0.5068\n",
      "Epoch 223/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6967 - acc: 0.5224 - val_loss: 0.6946 - val_acc: 0.5048\n",
      "Epoch 224/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5369 - val_loss: 0.6946 - val_acc: 0.5029\n",
      "Epoch 225/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6980 - acc: 0.5114 - val_loss: 0.6947 - val_acc: 0.5039\n",
      "Epoch 226/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6952 - acc: 0.5209 - val_loss: 0.6947 - val_acc: 0.5029\n",
      "Epoch 227/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6987 - acc: 0.5163 - val_loss: 0.6943 - val_acc: 0.4990\n",
      "Epoch 228/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6974 - acc: 0.5183 - val_loss: 0.6945 - val_acc: 0.4981\n",
      "Epoch 229/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6960 - acc: 0.5145 - val_loss: 0.6946 - val_acc: 0.4913\n",
      "Epoch 230/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6992 - acc: 0.5098 - val_loss: 0.6945 - val_acc: 0.5019\n",
      "Epoch 231/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6978 - acc: 0.5158 - val_loss: 0.6944 - val_acc: 0.4971\n",
      "Epoch 232/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6988 - acc: 0.5072 - val_loss: 0.6944 - val_acc: 0.5048\n",
      "Epoch 233/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6968 - acc: 0.5198 - val_loss: 0.6945 - val_acc: 0.4913\n",
      "Epoch 234/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6971 - acc: 0.5117 - val_loss: 0.6943 - val_acc: 0.5039\n",
      "Epoch 235/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6967 - acc: 0.5146 - val_loss: 0.6946 - val_acc: 0.4932\n",
      "Epoch 236/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6965 - acc: 0.5174 - val_loss: 0.6945 - val_acc: 0.4981\n",
      "Epoch 237/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6949 - acc: 0.5192 - val_loss: 0.6946 - val_acc: 0.4952\n",
      "Epoch 238/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6968 - acc: 0.5127 - val_loss: 0.6945 - val_acc: 0.5019\n",
      "Epoch 239/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6948 - acc: 0.5225 - val_loss: 0.6945 - val_acc: 0.5029\n",
      "Epoch 240/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6990 - acc: 0.5101 - val_loss: 0.6946 - val_acc: 0.5039\n",
      "Epoch 241/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6984 - acc: 0.5080 - val_loss: 0.6945 - val_acc: 0.4990\n",
      "Epoch 242/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6964 - acc: 0.5116 - val_loss: 0.6945 - val_acc: 0.5029\n",
      "Epoch 243/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6983 - acc: 0.5092 - val_loss: 0.6945 - val_acc: 0.5058\n",
      "Epoch 244/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6958 - acc: 0.5233 - val_loss: 0.6945 - val_acc: 0.4990\n",
      "Epoch 245/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6960 - acc: 0.5082 - val_loss: 0.6945 - val_acc: 0.5097\n",
      "Epoch 246/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6951 - acc: 0.5220 - val_loss: 0.6945 - val_acc: 0.5048\n",
      "Epoch 247/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6924 - acc: 0.5354 - val_loss: 0.6946 - val_acc: 0.4990\n",
      "Epoch 248/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6944 - acc: 0.5240 - val_loss: 0.6944 - val_acc: 0.5010\n",
      "Epoch 249/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6934 - acc: 0.5335 - val_loss: 0.6943 - val_acc: 0.5019\n",
      "Epoch 250/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6977 - acc: 0.5192 - val_loss: 0.6942 - val_acc: 0.5097\n",
      "Epoch 251/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6954 - acc: 0.5211 - val_loss: 0.6943 - val_acc: 0.5077\n",
      "Epoch 252/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6977 - acc: 0.5203 - val_loss: 0.6942 - val_acc: 0.5068\n",
      "Epoch 253/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6940 - acc: 0.5183 - val_loss: 0.6942 - val_acc: 0.4971\n",
      "Epoch 254/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6940 - acc: 0.5240 - val_loss: 0.6941 - val_acc: 0.5077\n",
      "Epoch 255/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6930 - acc: 0.5333 - val_loss: 0.6940 - val_acc: 0.5077\n",
      "Epoch 256/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6938 - acc: 0.5224 - val_loss: 0.6941 - val_acc: 0.5058\n",
      "Epoch 257/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6955 - acc: 0.5209 - val_loss: 0.6941 - val_acc: 0.5126\n",
      "Epoch 258/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6949 - acc: 0.5183 - val_loss: 0.6939 - val_acc: 0.5087\n",
      "Epoch 259/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6935 - acc: 0.5204 - val_loss: 0.6937 - val_acc: 0.5077\n",
      "Epoch 260/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5116\n",
      "Epoch 261/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6948 - acc: 0.5185 - val_loss: 0.6937 - val_acc: 0.5126\n",
      "Epoch 262/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6942 - acc: 0.5248 - val_loss: 0.6938 - val_acc: 0.5097\n",
      "Epoch 263/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6941 - acc: 0.5142 - val_loss: 0.6936 - val_acc: 0.5087\n",
      "Epoch 264/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6941 - acc: 0.5246 - val_loss: 0.6938 - val_acc: 0.5068\n",
      "Epoch 265/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6930 - acc: 0.5266 - val_loss: 0.6937 - val_acc: 0.5029\n",
      "Epoch 266/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6945 - acc: 0.5235 - val_loss: 0.6936 - val_acc: 0.5077\n",
      "Epoch 267/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6938 - acc: 0.5121 - val_loss: 0.6936 - val_acc: 0.5087\n",
      "Epoch 268/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6976 - acc: 0.5201 - val_loss: 0.6936 - val_acc: 0.5039\n",
      "Epoch 269/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6940 - acc: 0.5169 - val_loss: 0.6937 - val_acc: 0.5058\n",
      "Epoch 270/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6927 - acc: 0.5219 - val_loss: 0.6938 - val_acc: 0.5029\n",
      "Epoch 271/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6962 - acc: 0.5167 - val_loss: 0.6935 - val_acc: 0.5087\n",
      "Epoch 272/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6970 - acc: 0.5180 - val_loss: 0.6935 - val_acc: 0.5048\n",
      "Epoch 273/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6934 - acc: 0.5233 - val_loss: 0.6937 - val_acc: 0.5097\n",
      "Epoch 274/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6949 - acc: 0.5161 - val_loss: 0.6937 - val_acc: 0.4990\n",
      "Epoch 275/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6957 - acc: 0.5175 - val_loss: 0.6937 - val_acc: 0.5029\n",
      "Epoch 276/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6934 - acc: 0.5235 - val_loss: 0.6937 - val_acc: 0.4971\n",
      "Epoch 277/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6963 - acc: 0.5151 - val_loss: 0.6938 - val_acc: 0.4990\n",
      "Epoch 278/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6941 - acc: 0.5198 - val_loss: 0.6938 - val_acc: 0.5048\n",
      "Epoch 279/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6947 - acc: 0.5198 - val_loss: 0.6937 - val_acc: 0.5039\n",
      "Epoch 280/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6918 - acc: 0.5333 - val_loss: 0.6936 - val_acc: 0.4990\n",
      "Epoch 281/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6944 - acc: 0.5185 - val_loss: 0.6937 - val_acc: 0.4981\n",
      "Epoch 282/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6969 - acc: 0.5108 - val_loss: 0.6939 - val_acc: 0.4971\n",
      "Epoch 283/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6936 - acc: 0.5249 - val_loss: 0.6939 - val_acc: 0.5029\n",
      "Epoch 284/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6966 - acc: 0.5177 - val_loss: 0.6939 - val_acc: 0.4981\n",
      "Epoch 285/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6941 - acc: 0.5164 - val_loss: 0.6937 - val_acc: 0.4971\n",
      "Epoch 286/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6953 - acc: 0.5220 - val_loss: 0.6937 - val_acc: 0.5058\n",
      "Epoch 287/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6920 - acc: 0.5351 - val_loss: 0.6937 - val_acc: 0.4971\n",
      "Epoch 288/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6940 - acc: 0.5153 - val_loss: 0.6938 - val_acc: 0.4981\n",
      "Epoch 289/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6937 - acc: 0.5262 - val_loss: 0.6936 - val_acc: 0.5029\n",
      "Epoch 290/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6944 - acc: 0.5212 - val_loss: 0.6936 - val_acc: 0.5010\n",
      "Epoch 291/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6941 - acc: 0.5211 - val_loss: 0.6934 - val_acc: 0.5029\n",
      "Epoch 292/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6952 - acc: 0.5183 - val_loss: 0.6935 - val_acc: 0.5087\n",
      "Epoch 293/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6948 - acc: 0.5245 - val_loss: 0.6935 - val_acc: 0.5058\n",
      "Epoch 294/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6937 - acc: 0.5238 - val_loss: 0.6935 - val_acc: 0.5077\n",
      "Epoch 295/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6915 - acc: 0.5264 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 296/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6906 - acc: 0.5364 - val_loss: 0.6933 - val_acc: 0.5010\n",
      "Epoch 297/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6945 - acc: 0.5251 - val_loss: 0.6932 - val_acc: 0.5058\n",
      "Epoch 298/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6950 - acc: 0.5188 - val_loss: 0.6933 - val_acc: 0.5058\n",
      "Epoch 299/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6920 - acc: 0.5280 - val_loss: 0.6933 - val_acc: 0.5010\n",
      "Epoch 300/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6934 - acc: 0.5188 - val_loss: 0.6933 - val_acc: 0.5010\n",
      "Epoch 301/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6952 - acc: 0.5172 - val_loss: 0.6933 - val_acc: 0.5077\n",
      "Epoch 302/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6929 - acc: 0.5233 - val_loss: 0.6933 - val_acc: 0.4981\n",
      "Epoch 303/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6922 - acc: 0.5338 - val_loss: 0.6934 - val_acc: 0.5068\n",
      "Epoch 304/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6949 - acc: 0.5214 - val_loss: 0.6933 - val_acc: 0.5116\n",
      "Epoch 305/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6952 - acc: 0.5167 - val_loss: 0.6933 - val_acc: 0.5097\n",
      "Epoch 306/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6954 - acc: 0.5142 - val_loss: 0.6932 - val_acc: 0.5087\n",
      "Epoch 307/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6915 - acc: 0.5286 - val_loss: 0.6933 - val_acc: 0.5077\n",
      "Epoch 308/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6928 - acc: 0.5217 - val_loss: 0.6934 - val_acc: 0.5135\n",
      "Epoch 309/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6948 - acc: 0.5124 - val_loss: 0.6934 - val_acc: 0.5058\n",
      "Epoch 310/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6939 - acc: 0.5163 - val_loss: 0.6932 - val_acc: 0.5058\n",
      "Epoch 311/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6963 - acc: 0.5092 - val_loss: 0.6932 - val_acc: 0.5058\n",
      "Epoch 312/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6944 - acc: 0.5261 - val_loss: 0.6931 - val_acc: 0.5010\n",
      "Epoch 313/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6965 - acc: 0.5093 - val_loss: 0.6931 - val_acc: 0.5106\n",
      "Epoch 314/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6905 - acc: 0.5393 - val_loss: 0.6931 - val_acc: 0.5058\n",
      "Epoch 315/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6909 - acc: 0.5278 - val_loss: 0.6932 - val_acc: 0.5029\n",
      "Epoch 316/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6928 - acc: 0.5249 - val_loss: 0.6932 - val_acc: 0.5048\n",
      "Epoch 317/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6917 - acc: 0.5280 - val_loss: 0.6932 - val_acc: 0.5087\n",
      "Epoch 318/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6939 - acc: 0.5259 - val_loss: 0.6932 - val_acc: 0.5010\n",
      "Epoch 319/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6928 - acc: 0.5245 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 320/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6917 - acc: 0.5237 - val_loss: 0.6932 - val_acc: 0.4990\n",
      "Epoch 321/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6928 - acc: 0.5259 - val_loss: 0.6933 - val_acc: 0.5048\n",
      "Epoch 322/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6924 - acc: 0.5225 - val_loss: 0.6933 - val_acc: 0.5048\n",
      "Epoch 323/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6923 - acc: 0.5204 - val_loss: 0.6933 - val_acc: 0.5077\n",
      "Epoch 324/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6910 - acc: 0.5262 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 325/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6923 - acc: 0.5278 - val_loss: 0.6932 - val_acc: 0.5068\n",
      "Epoch 326/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6926 - acc: 0.5266 - val_loss: 0.6932 - val_acc: 0.5097\n",
      "Epoch 327/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6950 - acc: 0.5146 - val_loss: 0.6929 - val_acc: 0.5077\n",
      "Epoch 328/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6948 - acc: 0.5183 - val_loss: 0.6930 - val_acc: 0.5019\n",
      "Epoch 329/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6915 - acc: 0.5299 - val_loss: 0.6931 - val_acc: 0.5077\n",
      "Epoch 330/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6917 - acc: 0.5303 - val_loss: 0.6930 - val_acc: 0.5068\n",
      "Epoch 331/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6911 - acc: 0.5285 - val_loss: 0.6929 - val_acc: 0.5068\n",
      "Epoch 332/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6936 - acc: 0.5187 - val_loss: 0.6929 - val_acc: 0.5058\n",
      "Epoch 333/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6932 - acc: 0.5256 - val_loss: 0.6929 - val_acc: 0.5039\n",
      "Epoch 334/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6931 - acc: 0.5198 - val_loss: 0.6929 - val_acc: 0.4990\n",
      "Epoch 335/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6944 - acc: 0.5151 - val_loss: 0.6930 - val_acc: 0.4961\n",
      "Epoch 336/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6946 - acc: 0.5134 - val_loss: 0.6929 - val_acc: 0.5000\n",
      "Epoch 337/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6931 - acc: 0.5214 - val_loss: 0.6929 - val_acc: 0.4990\n",
      "Epoch 338/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6939 - acc: 0.5111 - val_loss: 0.6929 - val_acc: 0.5058\n",
      "Epoch 339/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6929 - acc: 0.5212 - val_loss: 0.6928 - val_acc: 0.5039\n",
      "Epoch 340/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6941 - acc: 0.5171 - val_loss: 0.6928 - val_acc: 0.5077\n",
      "Epoch 341/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6944 - acc: 0.5203 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 342/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6903 - acc: 0.5349 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 343/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6924 - acc: 0.5248 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 344/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6939 - acc: 0.5185 - val_loss: 0.6927 - val_acc: 0.5077\n",
      "Epoch 345/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6939 - acc: 0.5132 - val_loss: 0.6926 - val_acc: 0.5068\n",
      "Epoch 346/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5278 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 347/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6915 - acc: 0.5220 - val_loss: 0.6928 - val_acc: 0.5010\n",
      "Epoch 348/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6923 - acc: 0.5175 - val_loss: 0.6927 - val_acc: 0.5029\n",
      "Epoch 349/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6912 - acc: 0.5200 - val_loss: 0.6926 - val_acc: 0.5058\n",
      "Epoch 350/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6959 - acc: 0.5187 - val_loss: 0.6927 - val_acc: 0.5087\n",
      "Epoch 351/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6912 - acc: 0.5290 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 352/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6913 - acc: 0.5264 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 353/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6910 - acc: 0.5222 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 354/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5336 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 355/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6886 - acc: 0.5426 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 356/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6938 - acc: 0.5145 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 357/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6899 - acc: 0.5346 - val_loss: 0.6929 - val_acc: 0.5039\n",
      "Epoch 358/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6884 - acc: 0.5341 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 359/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6924 - acc: 0.5232 - val_loss: 0.6928 - val_acc: 0.5155\n",
      "Epoch 360/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6924 - acc: 0.5262 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 361/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6906 - acc: 0.5280 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 362/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6892 - acc: 0.5264 - val_loss: 0.6926 - val_acc: 0.5145\n",
      "Epoch 363/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6906 - acc: 0.5294 - val_loss: 0.6926 - val_acc: 0.5097\n",
      "Epoch 364/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5375 - val_loss: 0.6926 - val_acc: 0.5077\n",
      "Epoch 365/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6908 - acc: 0.5283 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 366/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6912 - acc: 0.5288 - val_loss: 0.6927 - val_acc: 0.5048\n",
      "Epoch 367/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5198 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 368/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6907 - acc: 0.5333 - val_loss: 0.6926 - val_acc: 0.5135\n",
      "Epoch 369/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6910 - acc: 0.5333 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 370/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6916 - acc: 0.5322 - val_loss: 0.6927 - val_acc: 0.5184\n",
      "Epoch 371/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6920 - acc: 0.5267 - val_loss: 0.6928 - val_acc: 0.5077\n",
      "Epoch 372/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6943 - acc: 0.5214 - val_loss: 0.6928 - val_acc: 0.5039\n",
      "Epoch 373/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6932 - acc: 0.5175 - val_loss: 0.6929 - val_acc: 0.5184\n",
      "Epoch 374/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6943 - acc: 0.5122 - val_loss: 0.6926 - val_acc: 0.5155\n",
      "Epoch 375/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6916 - acc: 0.5227 - val_loss: 0.6928 - val_acc: 0.5155\n",
      "Epoch 376/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6925 - acc: 0.5183 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 377/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6924 - acc: 0.5225 - val_loss: 0.6929 - val_acc: 0.5077\n",
      "Epoch 378/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6931 - acc: 0.5208 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 379/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6897 - acc: 0.5319 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 380/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6919 - acc: 0.5290 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 381/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6918 - acc: 0.5220 - val_loss: 0.6928 - val_acc: 0.5087\n",
      "Epoch 382/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6901 - acc: 0.5311 - val_loss: 0.6929 - val_acc: 0.5068\n",
      "Epoch 383/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6920 - acc: 0.5269 - val_loss: 0.6927 - val_acc: 0.5077\n",
      "Epoch 384/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6893 - acc: 0.5220 - val_loss: 0.6927 - val_acc: 0.5077\n",
      "Epoch 385/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6923 - acc: 0.5262 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 386/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6893 - acc: 0.5298 - val_loss: 0.6926 - val_acc: 0.5097\n",
      "Epoch 387/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5340 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 388/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6919 - acc: 0.5253 - val_loss: 0.6928 - val_acc: 0.5048\n",
      "Epoch 389/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6905 - acc: 0.5312 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 390/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.6927 - val_acc: 0.5068\n",
      "Epoch 391/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6938 - acc: 0.5198 - val_loss: 0.6928 - val_acc: 0.5077\n",
      "Epoch 392/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5293 - val_loss: 0.6928 - val_acc: 0.5039\n",
      "Epoch 393/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6898 - acc: 0.5243 - val_loss: 0.6926 - val_acc: 0.5097\n",
      "Epoch 394/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5394 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 395/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6930 - acc: 0.5150 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 396/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5335 - val_loss: 0.6927 - val_acc: 0.5058\n",
      "Epoch 397/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6926 - acc: 0.5238 - val_loss: 0.6928 - val_acc: 0.5048\n",
      "Epoch 398/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5238 - val_loss: 0.6927 - val_acc: 0.5077\n",
      "Epoch 399/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6911 - acc: 0.5264 - val_loss: 0.6927 - val_acc: 0.5068\n",
      "Epoch 400/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6921 - acc: 0.5304 - val_loss: 0.6928 - val_acc: 0.5068\n",
      "Epoch 401/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5319 - val_loss: 0.6929 - val_acc: 0.5048\n",
      "Epoch 402/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6909 - acc: 0.5246 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 403/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6904 - acc: 0.5386 - val_loss: 0.6928 - val_acc: 0.5106\n",
      "Epoch 404/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6925 - acc: 0.5277 - val_loss: 0.6928 - val_acc: 0.5077\n",
      "Epoch 405/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6900 - acc: 0.5311 - val_loss: 0.6929 - val_acc: 0.5058\n",
      "Epoch 406/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6910 - acc: 0.5259 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 407/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6910 - acc: 0.5280 - val_loss: 0.6928 - val_acc: 0.5077\n",
      "Epoch 408/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5426 - val_loss: 0.6930 - val_acc: 0.5145\n",
      "Epoch 409/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6917 - acc: 0.5164 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 410/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6921 - acc: 0.5196 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 411/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6921 - acc: 0.5270 - val_loss: 0.6930 - val_acc: 0.5135\n",
      "Epoch 412/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6910 - acc: 0.5286 - val_loss: 0.6928 - val_acc: 0.5126\n",
      "Epoch 413/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6911 - acc: 0.5304 - val_loss: 0.6927 - val_acc: 0.5077\n",
      "Epoch 414/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5325 - val_loss: 0.6927 - val_acc: 0.5164\n",
      "Epoch 415/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5401 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 416/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5243 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 417/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6918 - acc: 0.5216 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 418/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6917 - acc: 0.5285 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 419/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6912 - acc: 0.5332 - val_loss: 0.6928 - val_acc: 0.5087\n",
      "Epoch 420/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6906 - acc: 0.5288 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 421/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6905 - acc: 0.5217 - val_loss: 0.6928 - val_acc: 0.5068\n",
      "Epoch 422/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6904 - acc: 0.5243 - val_loss: 0.6927 - val_acc: 0.5087\n",
      "Epoch 423/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6887 - acc: 0.5369 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 424/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6911 - acc: 0.5301 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 425/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6892 - acc: 0.5306 - val_loss: 0.6928 - val_acc: 0.5029\n",
      "Epoch 426/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6927 - acc: 0.5192 - val_loss: 0.6929 - val_acc: 0.5087\n",
      "Epoch 427/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5369 - val_loss: 0.6929 - val_acc: 0.5087\n",
      "Epoch 428/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6906 - acc: 0.5248 - val_loss: 0.6928 - val_acc: 0.5126\n",
      "Epoch 429/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6898 - acc: 0.5344 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 430/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5330 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 431/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5303 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 432/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6907 - acc: 0.5233 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 433/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5359 - val_loss: 0.6927 - val_acc: 0.5068\n",
      "Epoch 434/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6920 - acc: 0.5243 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 435/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6917 - acc: 0.5285 - val_loss: 0.6927 - val_acc: 0.5048\n",
      "Epoch 436/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6898 - acc: 0.5370 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 437/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6897 - acc: 0.5348 - val_loss: 0.6926 - val_acc: 0.5068\n",
      "Epoch 438/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6920 - acc: 0.5311 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 439/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6877 - acc: 0.5454 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 440/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5253 - val_loss: 0.6926 - val_acc: 0.5077\n",
      "Epoch 441/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5399 - val_loss: 0.6926 - val_acc: 0.5155\n",
      "Epoch 442/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6889 - acc: 0.5412 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 443/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6904 - acc: 0.5286 - val_loss: 0.6926 - val_acc: 0.5068\n",
      "Epoch 444/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6891 - acc: 0.5328 - val_loss: 0.6925 - val_acc: 0.5058\n",
      "Epoch 445/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6866 - acc: 0.5452 - val_loss: 0.6926 - val_acc: 0.5068\n",
      "Epoch 446/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6903 - acc: 0.5299 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 447/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6911 - acc: 0.5270 - val_loss: 0.6926 - val_acc: 0.5077\n",
      "Epoch 448/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5262 - val_loss: 0.6926 - val_acc: 0.5039\n",
      "Epoch 449/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5319 - val_loss: 0.6926 - val_acc: 0.5145\n",
      "Epoch 450/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6901 - acc: 0.5307 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 451/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6903 - acc: 0.5248 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 452/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6888 - acc: 0.5317 - val_loss: 0.6925 - val_acc: 0.5135\n",
      "Epoch 453/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5341 - val_loss: 0.6925 - val_acc: 0.5116\n",
      "Epoch 454/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6908 - acc: 0.5249 - val_loss: 0.6925 - val_acc: 0.5135\n",
      "Epoch 455/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6893 - acc: 0.5370 - val_loss: 0.6925 - val_acc: 0.5087\n",
      "Epoch 456/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5317 - val_loss: 0.6925 - val_acc: 0.5097\n",
      "Epoch 457/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5304 - val_loss: 0.6925 - val_acc: 0.5068\n",
      "Epoch 458/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6912 - acc: 0.5227 - val_loss: 0.6925 - val_acc: 0.5087\n",
      "Epoch 459/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5356 - val_loss: 0.6924 - val_acc: 0.5145\n",
      "Epoch 460/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6904 - acc: 0.5306 - val_loss: 0.6925 - val_acc: 0.5155\n",
      "Epoch 461/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6901 - acc: 0.5254 - val_loss: 0.6926 - val_acc: 0.5058\n",
      "Epoch 462/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5314 - val_loss: 0.6925 - val_acc: 0.5048\n",
      "Epoch 463/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6898 - acc: 0.5290 - val_loss: 0.6925 - val_acc: 0.5087\n",
      "Epoch 464/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6920 - acc: 0.5220 - val_loss: 0.6924 - val_acc: 0.5087\n",
      "Epoch 465/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5320 - val_loss: 0.6924 - val_acc: 0.5116\n",
      "Epoch 466/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6932 - acc: 0.5159 - val_loss: 0.6924 - val_acc: 0.5087\n",
      "Epoch 467/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5352 - val_loss: 0.6923 - val_acc: 0.5019\n",
      "Epoch 468/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6908 - acc: 0.5294 - val_loss: 0.6923 - val_acc: 0.5135\n",
      "Epoch 469/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6900 - acc: 0.5232 - val_loss: 0.6925 - val_acc: 0.5135\n",
      "Epoch 470/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6887 - acc: 0.5335 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 471/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6914 - acc: 0.5325 - val_loss: 0.6925 - val_acc: 0.5058\n",
      "Epoch 472/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6916 - acc: 0.5241 - val_loss: 0.6926 - val_acc: 0.5155\n",
      "Epoch 473/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5423 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 474/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6892 - acc: 0.5380 - val_loss: 0.6926 - val_acc: 0.5155\n",
      "Epoch 475/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6911 - acc: 0.5325 - val_loss: 0.6926 - val_acc: 0.5155\n",
      "Epoch 476/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6919 - acc: 0.5227 - val_loss: 0.6926 - val_acc: 0.5164\n",
      "Epoch 477/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5293 - val_loss: 0.6926 - val_acc: 0.5184\n",
      "Epoch 478/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6885 - acc: 0.5378 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 479/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6868 - acc: 0.5389 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 480/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6893 - acc: 0.5369 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 481/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6911 - acc: 0.5294 - val_loss: 0.6926 - val_acc: 0.5135\n",
      "Epoch 482/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6897 - acc: 0.5332 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 483/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5423 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 484/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6886 - acc: 0.5386 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 485/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6877 - acc: 0.5446 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 486/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6878 - acc: 0.5444 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 487/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6904 - acc: 0.5256 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 488/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5304 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 489/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6877 - acc: 0.5399 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 490/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6879 - acc: 0.5359 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 491/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5320 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 492/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6892 - acc: 0.5335 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 493/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6901 - acc: 0.5286 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 494/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6902 - acc: 0.5332 - val_loss: 0.6927 - val_acc: 0.5193\n",
      "Epoch 495/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6883 - acc: 0.5349 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 496/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6872 - acc: 0.5447 - val_loss: 0.6928 - val_acc: 0.5184\n",
      "Epoch 497/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5341 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 498/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6887 - acc: 0.5372 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 499/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6893 - acc: 0.5391 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 500/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6881 - acc: 0.5406 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 501/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6884 - acc: 0.5383 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 502/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6888 - acc: 0.5293 - val_loss: 0.6927 - val_acc: 0.5164\n",
      "Epoch 503/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5356 - val_loss: 0.6928 - val_acc: 0.5077\n",
      "Epoch 504/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5364 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 505/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6894 - acc: 0.5348 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 506/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6885 - acc: 0.5349 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 507/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6881 - acc: 0.5383 - val_loss: 0.6929 - val_acc: 0.5213\n",
      "Epoch 508/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6918 - acc: 0.5278 - val_loss: 0.6930 - val_acc: 0.5155\n",
      "Epoch 509/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5283 - val_loss: 0.6929 - val_acc: 0.5087\n",
      "Epoch 510/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6870 - acc: 0.5373 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 511/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6895 - acc: 0.5352 - val_loss: 0.6929 - val_acc: 0.5126\n",
      "Epoch 512/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6891 - acc: 0.5370 - val_loss: 0.6929 - val_acc: 0.5155\n",
      "Epoch 513/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6901 - acc: 0.5383 - val_loss: 0.6930 - val_acc: 0.5145\n",
      "Epoch 514/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6891 - acc: 0.5328 - val_loss: 0.6929 - val_acc: 0.5135\n",
      "Epoch 515/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6904 - acc: 0.5323 - val_loss: 0.6929 - val_acc: 0.5174\n",
      "Epoch 516/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6884 - acc: 0.5378 - val_loss: 0.6929 - val_acc: 0.5174\n",
      "Epoch 517/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6901 - acc: 0.5351 - val_loss: 0.6929 - val_acc: 0.5135\n",
      "Epoch 518/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5336 - val_loss: 0.6929 - val_acc: 0.5135\n",
      "Epoch 519/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5481 - val_loss: 0.6930 - val_acc: 0.5193\n",
      "Epoch 520/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5333 - val_loss: 0.6930 - val_acc: 0.5135\n",
      "Epoch 521/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6869 - acc: 0.5407 - val_loss: 0.6930 - val_acc: 0.5184\n",
      "Epoch 522/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6889 - acc: 0.5323 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 523/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6903 - acc: 0.5314 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 524/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6874 - acc: 0.5420 - val_loss: 0.6929 - val_acc: 0.5097\n",
      "Epoch 525/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6897 - acc: 0.5344 - val_loss: 0.6929 - val_acc: 0.5145\n",
      "Epoch 526/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6900 - acc: 0.5328 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 527/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6885 - acc: 0.5336 - val_loss: 0.6930 - val_acc: 0.5106\n",
      "Epoch 528/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6888 - acc: 0.5312 - val_loss: 0.6929 - val_acc: 0.5145\n",
      "Epoch 529/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6875 - acc: 0.5467 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 530/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6888 - acc: 0.5360 - val_loss: 0.6929 - val_acc: 0.5106\n",
      "Epoch 531/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6905 - acc: 0.5306 - val_loss: 0.6928 - val_acc: 0.5184\n",
      "Epoch 532/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6893 - acc: 0.5319 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 533/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6882 - acc: 0.5365 - val_loss: 0.6928 - val_acc: 0.5164\n",
      "Epoch 534/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6881 - acc: 0.5377 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 535/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6887 - acc: 0.5431 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 536/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5383 - val_loss: 0.6928 - val_acc: 0.5097\n",
      "Epoch 537/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5298 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 538/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6882 - acc: 0.5286 - val_loss: 0.6928 - val_acc: 0.5106\n",
      "Epoch 539/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6896 - acc: 0.5312 - val_loss: 0.6929 - val_acc: 0.5077\n",
      "Epoch 540/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6891 - acc: 0.5356 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 541/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6895 - acc: 0.5301 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 542/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5410 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 543/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6898 - acc: 0.5293 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 544/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6871 - acc: 0.5394 - val_loss: 0.6927 - val_acc: 0.5164\n",
      "Epoch 545/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6926 - acc: 0.5285 - val_loss: 0.6927 - val_acc: 0.5174\n",
      "Epoch 546/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6881 - acc: 0.5397 - val_loss: 0.6929 - val_acc: 0.5184\n",
      "Epoch 547/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6891 - acc: 0.5349 - val_loss: 0.6927 - val_acc: 0.5174\n",
      "Epoch 548/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6882 - acc: 0.5261 - val_loss: 0.6926 - val_acc: 0.5164\n",
      "Epoch 549/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6906 - acc: 0.5251 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 550/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6867 - acc: 0.5520 - val_loss: 0.6929 - val_acc: 0.5213\n",
      "Epoch 551/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5417 - val_loss: 0.6929 - val_acc: 0.5164\n",
      "Epoch 552/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6879 - acc: 0.5335 - val_loss: 0.6929 - val_acc: 0.5164\n",
      "Epoch 553/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6876 - acc: 0.5430 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 554/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5285 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 555/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5394 - val_loss: 0.6929 - val_acc: 0.5135\n",
      "Epoch 556/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5360 - val_loss: 0.6929 - val_acc: 0.5116\n",
      "Epoch 557/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6876 - acc: 0.5438 - val_loss: 0.6928 - val_acc: 0.5164\n",
      "Epoch 558/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5380 - val_loss: 0.6928 - val_acc: 0.5106\n",
      "Epoch 559/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6903 - acc: 0.5257 - val_loss: 0.6928 - val_acc: 0.5106\n",
      "Epoch 560/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6882 - acc: 0.5369 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 561/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6891 - acc: 0.5386 - val_loss: 0.6927 - val_acc: 0.5203\n",
      "Epoch 562/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6882 - acc: 0.5298 - val_loss: 0.6927 - val_acc: 0.5145\n",
      "Epoch 563/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6867 - acc: 0.5412 - val_loss: 0.6928 - val_acc: 0.5145\n",
      "Epoch 564/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6876 - acc: 0.5362 - val_loss: 0.6928 - val_acc: 0.5164\n",
      "Epoch 565/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5378 - val_loss: 0.6928 - val_acc: 0.5164\n",
      "Epoch 566/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5393 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 567/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6866 - acc: 0.5372 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 568/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5407 - val_loss: 0.6927 - val_acc: 0.5184\n",
      "Epoch 569/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6882 - acc: 0.5436 - val_loss: 0.6926 - val_acc: 0.5203\n",
      "Epoch 570/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6869 - acc: 0.5425 - val_loss: 0.6927 - val_acc: 0.5193\n",
      "Epoch 571/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6883 - acc: 0.5352 - val_loss: 0.6926 - val_acc: 0.5184\n",
      "Epoch 572/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6869 - acc: 0.5362 - val_loss: 0.6926 - val_acc: 0.5193\n",
      "Epoch 573/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5274 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 574/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6884 - acc: 0.5357 - val_loss: 0.6926 - val_acc: 0.5174\n",
      "Epoch 575/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6870 - acc: 0.5422 - val_loss: 0.6926 - val_acc: 0.5164\n",
      "Epoch 576/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5364 - val_loss: 0.6926 - val_acc: 0.5174\n",
      "Epoch 577/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6898 - acc: 0.5375 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 578/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6857 - acc: 0.5406 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 579/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6876 - acc: 0.5323 - val_loss: 0.6928 - val_acc: 0.5193\n",
      "Epoch 580/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6883 - acc: 0.5328 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 581/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6894 - acc: 0.5327 - val_loss: 0.6927 - val_acc: 0.5164\n",
      "Epoch 582/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6872 - acc: 0.5430 - val_loss: 0.6927 - val_acc: 0.5174\n",
      "Epoch 583/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6879 - acc: 0.5285 - val_loss: 0.6928 - val_acc: 0.5135\n",
      "Epoch 584/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6883 - acc: 0.5365 - val_loss: 0.6926 - val_acc: 0.5155\n",
      "Epoch 585/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5412 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 586/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6891 - acc: 0.5340 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 587/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5352 - val_loss: 0.6927 - val_acc: 0.5116\n",
      "Epoch 588/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6865 - acc: 0.5340 - val_loss: 0.6928 - val_acc: 0.5126\n",
      "Epoch 589/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6877 - acc: 0.5352 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 590/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5340 - val_loss: 0.6927 - val_acc: 0.5164\n",
      "Epoch 591/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6845 - acc: 0.5618 - val_loss: 0.6928 - val_acc: 0.5116\n",
      "Epoch 592/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6876 - acc: 0.5399 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 593/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5386 - val_loss: 0.6927 - val_acc: 0.5184\n",
      "Epoch 594/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6885 - acc: 0.5317 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 595/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6873 - acc: 0.5410 - val_loss: 0.6926 - val_acc: 0.5145\n",
      "Epoch 596/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5380 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 597/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6868 - acc: 0.5438 - val_loss: 0.6928 - val_acc: 0.5155\n",
      "Epoch 598/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5475 - val_loss: 0.6928 - val_acc: 0.5164\n",
      "Epoch 599/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6866 - acc: 0.5364 - val_loss: 0.6927 - val_acc: 0.5106\n",
      "Epoch 600/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6876 - acc: 0.5372 - val_loss: 0.6927 - val_acc: 0.5126\n",
      "Epoch 601/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6873 - acc: 0.5401 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 602/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5352 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 603/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6874 - acc: 0.5423 - val_loss: 0.6926 - val_acc: 0.5135\n",
      "Epoch 604/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6862 - acc: 0.5356 - val_loss: 0.6926 - val_acc: 0.5097\n",
      "Epoch 605/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6867 - acc: 0.5431 - val_loss: 0.6925 - val_acc: 0.5106\n",
      "Epoch 606/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6853 - acc: 0.5385 - val_loss: 0.6924 - val_acc: 0.5087\n",
      "Epoch 607/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6867 - acc: 0.5414 - val_loss: 0.6924 - val_acc: 0.5058\n",
      "Epoch 608/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6889 - acc: 0.5301 - val_loss: 0.6925 - val_acc: 0.5077\n",
      "Epoch 609/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6896 - acc: 0.5323 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 610/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6886 - acc: 0.5356 - val_loss: 0.6924 - val_acc: 0.5106\n",
      "Epoch 611/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5410 - val_loss: 0.6924 - val_acc: 0.5135\n",
      "Epoch 612/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6874 - acc: 0.5402 - val_loss: 0.6924 - val_acc: 0.5068\n",
      "Epoch 613/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6885 - acc: 0.5296 - val_loss: 0.6925 - val_acc: 0.5155\n",
      "Epoch 614/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6852 - acc: 0.5425 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 615/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6866 - acc: 0.5439 - val_loss: 0.6925 - val_acc: 0.5145\n",
      "Epoch 616/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6881 - acc: 0.5378 - val_loss: 0.6924 - val_acc: 0.5106\n",
      "Epoch 617/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6883 - acc: 0.5404 - val_loss: 0.6925 - val_acc: 0.5106\n",
      "Epoch 618/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6867 - acc: 0.5412 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 619/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6867 - acc: 0.5447 - val_loss: 0.6925 - val_acc: 0.5106\n",
      "Epoch 620/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6887 - acc: 0.5340 - val_loss: 0.6925 - val_acc: 0.5135\n",
      "Epoch 621/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6868 - acc: 0.5338 - val_loss: 0.6926 - val_acc: 0.5077\n",
      "Epoch 622/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6867 - acc: 0.5389 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 623/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6863 - acc: 0.5436 - val_loss: 0.6924 - val_acc: 0.5106\n",
      "Epoch 624/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6856 - acc: 0.5502 - val_loss: 0.6925 - val_acc: 0.5106\n",
      "Epoch 625/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5459 - val_loss: 0.6925 - val_acc: 0.5135\n",
      "Epoch 626/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6843 - acc: 0.5510 - val_loss: 0.6925 - val_acc: 0.5145\n",
      "Epoch 627/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6870 - acc: 0.5332 - val_loss: 0.6925 - val_acc: 0.5145\n",
      "Epoch 628/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5330 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 629/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6889 - acc: 0.5264 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 630/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5499 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 631/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6877 - acc: 0.5365 - val_loss: 0.6926 - val_acc: 0.5097\n",
      "Epoch 632/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6862 - acc: 0.5369 - val_loss: 0.6925 - val_acc: 0.5106\n",
      "Epoch 633/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6859 - acc: 0.5460 - val_loss: 0.6926 - val_acc: 0.5106\n",
      "Epoch 634/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6867 - acc: 0.5446 - val_loss: 0.6925 - val_acc: 0.5058\n",
      "Epoch 635/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6888 - acc: 0.5418 - val_loss: 0.6927 - val_acc: 0.5087\n",
      "Epoch 636/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6852 - acc: 0.5438 - val_loss: 0.6926 - val_acc: 0.5097\n",
      "Epoch 637/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6879 - acc: 0.5391 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 638/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6857 - acc: 0.5500 - val_loss: 0.6925 - val_acc: 0.5077\n",
      "Epoch 639/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6863 - acc: 0.5418 - val_loss: 0.6926 - val_acc: 0.5058\n",
      "Epoch 640/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6855 - acc: 0.5436 - val_loss: 0.6926 - val_acc: 0.5068\n",
      "Epoch 641/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6858 - acc: 0.5523 - val_loss: 0.6926 - val_acc: 0.5087\n",
      "Epoch 642/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6863 - acc: 0.5444 - val_loss: 0.6925 - val_acc: 0.5077\n",
      "Epoch 643/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6862 - acc: 0.5391 - val_loss: 0.6927 - val_acc: 0.5097\n",
      "Epoch 644/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5402 - val_loss: 0.6925 - val_acc: 0.5116\n",
      "Epoch 645/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5365 - val_loss: 0.6926 - val_acc: 0.5126\n",
      "Epoch 646/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6849 - acc: 0.5504 - val_loss: 0.6925 - val_acc: 0.5145\n",
      "Epoch 647/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6855 - acc: 0.5444 - val_loss: 0.6925 - val_acc: 0.5155\n",
      "Epoch 648/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6877 - acc: 0.5377 - val_loss: 0.6924 - val_acc: 0.5174\n",
      "Epoch 649/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5438 - val_loss: 0.6925 - val_acc: 0.5155\n",
      "Epoch 650/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6869 - acc: 0.5359 - val_loss: 0.6924 - val_acc: 0.5164\n",
      "Epoch 651/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5462 - val_loss: 0.6924 - val_acc: 0.5213\n",
      "Epoch 652/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6872 - acc: 0.5372 - val_loss: 0.6923 - val_acc: 0.5232\n",
      "Epoch 653/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5491 - val_loss: 0.6924 - val_acc: 0.5174\n",
      "Epoch 654/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6874 - acc: 0.5373 - val_loss: 0.6925 - val_acc: 0.5174\n",
      "Epoch 655/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6839 - acc: 0.5562 - val_loss: 0.6924 - val_acc: 0.5184\n",
      "Epoch 656/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6884 - acc: 0.5362 - val_loss: 0.6925 - val_acc: 0.5232\n",
      "Epoch 657/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6855 - acc: 0.5441 - val_loss: 0.6926 - val_acc: 0.5193\n",
      "Epoch 658/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5397 - val_loss: 0.6925 - val_acc: 0.5193\n",
      "Epoch 659/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6844 - acc: 0.5462 - val_loss: 0.6925 - val_acc: 0.5203\n",
      "Epoch 660/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6869 - acc: 0.5414 - val_loss: 0.6925 - val_acc: 0.5213\n",
      "Epoch 661/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6866 - acc: 0.5425 - val_loss: 0.6925 - val_acc: 0.5203\n",
      "Epoch 662/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6845 - acc: 0.5504 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 663/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6883 - acc: 0.5346 - val_loss: 0.6925 - val_acc: 0.5280\n",
      "Epoch 664/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5412 - val_loss: 0.6925 - val_acc: 0.5222\n",
      "Epoch 665/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6899 - acc: 0.5319 - val_loss: 0.6925 - val_acc: 0.5232\n",
      "Epoch 666/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6857 - acc: 0.5359 - val_loss: 0.6926 - val_acc: 0.5261\n",
      "Epoch 667/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5394 - val_loss: 0.6927 - val_acc: 0.5271\n",
      "Epoch 668/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6846 - acc: 0.5484 - val_loss: 0.6927 - val_acc: 0.5251\n",
      "Epoch 669/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6866 - acc: 0.5397 - val_loss: 0.6926 - val_acc: 0.5319\n",
      "Epoch 670/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6872 - acc: 0.5401 - val_loss: 0.6926 - val_acc: 0.5309\n",
      "Epoch 671/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5454 - val_loss: 0.6927 - val_acc: 0.5213\n",
      "Epoch 672/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6894 - acc: 0.5356 - val_loss: 0.6925 - val_acc: 0.5271\n",
      "Epoch 673/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6860 - acc: 0.5367 - val_loss: 0.6925 - val_acc: 0.5193\n",
      "Epoch 674/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6856 - acc: 0.5491 - val_loss: 0.6925 - val_acc: 0.5300\n",
      "Epoch 675/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6866 - acc: 0.5414 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 676/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5412 - val_loss: 0.6925 - val_acc: 0.5261\n",
      "Epoch 677/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6856 - acc: 0.5454 - val_loss: 0.6924 - val_acc: 0.5300\n",
      "Epoch 678/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5431 - val_loss: 0.6924 - val_acc: 0.5309\n",
      "Epoch 679/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6851 - acc: 0.5439 - val_loss: 0.6925 - val_acc: 0.5309\n",
      "Epoch 680/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6855 - acc: 0.5354 - val_loss: 0.6925 - val_acc: 0.5271\n",
      "Epoch 681/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5397 - val_loss: 0.6925 - val_acc: 0.5222\n",
      "Epoch 682/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6867 - acc: 0.5441 - val_loss: 0.6926 - val_acc: 0.5309\n",
      "Epoch 683/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5518 - val_loss: 0.6927 - val_acc: 0.5261\n",
      "Epoch 684/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5521 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 685/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6853 - acc: 0.5401 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 686/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6862 - acc: 0.5422 - val_loss: 0.6926 - val_acc: 0.5300\n",
      "Epoch 687/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6865 - acc: 0.5406 - val_loss: 0.6925 - val_acc: 0.5251\n",
      "Epoch 688/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6852 - acc: 0.5436 - val_loss: 0.6925 - val_acc: 0.5242\n",
      "Epoch 689/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5486 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 690/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5500 - val_loss: 0.6926 - val_acc: 0.5329\n",
      "Epoch 691/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6883 - acc: 0.5476 - val_loss: 0.6927 - val_acc: 0.5309\n",
      "Epoch 692/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6853 - acc: 0.5510 - val_loss: 0.6925 - val_acc: 0.5232\n",
      "Epoch 693/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6832 - acc: 0.5478 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 694/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6848 - acc: 0.5399 - val_loss: 0.6926 - val_acc: 0.5280\n",
      "Epoch 695/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5422 - val_loss: 0.6927 - val_acc: 0.5135\n",
      "Epoch 696/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5610 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 697/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6884 - acc: 0.5422 - val_loss: 0.6925 - val_acc: 0.5213\n",
      "Epoch 698/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6860 - acc: 0.5460 - val_loss: 0.6927 - val_acc: 0.5251\n",
      "Epoch 699/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6868 - acc: 0.5431 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 700/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6852 - acc: 0.5447 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 701/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6851 - acc: 0.5529 - val_loss: 0.6926 - val_acc: 0.5251\n",
      "Epoch 702/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5404 - val_loss: 0.6927 - val_acc: 0.5155\n",
      "Epoch 703/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6852 - acc: 0.5435 - val_loss: 0.6927 - val_acc: 0.5184\n",
      "Epoch 704/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6890 - acc: 0.5365 - val_loss: 0.6925 - val_acc: 0.5261\n",
      "Epoch 705/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6851 - acc: 0.5478 - val_loss: 0.6927 - val_acc: 0.5251\n",
      "Epoch 706/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5483 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 707/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5478 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 708/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5377 - val_loss: 0.6926 - val_acc: 0.5280\n",
      "Epoch 709/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5367 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 710/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6854 - acc: 0.5463 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 711/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6853 - acc: 0.5470 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 712/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6850 - acc: 0.5452 - val_loss: 0.6928 - val_acc: 0.5232\n",
      "Epoch 713/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6864 - acc: 0.5406 - val_loss: 0.6927 - val_acc: 0.5261\n",
      "Epoch 714/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6854 - acc: 0.5397 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 715/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6882 - acc: 0.5386 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 716/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6867 - acc: 0.5475 - val_loss: 0.6928 - val_acc: 0.5261\n",
      "Epoch 717/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5500 - val_loss: 0.6929 - val_acc: 0.5251\n",
      "Epoch 718/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6856 - acc: 0.5454 - val_loss: 0.6928 - val_acc: 0.5261\n",
      "Epoch 719/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6859 - acc: 0.5412 - val_loss: 0.6928 - val_acc: 0.5222\n",
      "Epoch 720/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6881 - acc: 0.5290 - val_loss: 0.6929 - val_acc: 0.5193\n",
      "Epoch 721/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6862 - acc: 0.5377 - val_loss: 0.6927 - val_acc: 0.5213\n",
      "Epoch 722/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6835 - acc: 0.5470 - val_loss: 0.6928 - val_acc: 0.5232\n",
      "Epoch 723/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6849 - acc: 0.5438 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 724/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5446 - val_loss: 0.6929 - val_acc: 0.5213\n",
      "Epoch 725/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6855 - acc: 0.5399 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 726/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5531 - val_loss: 0.6927 - val_acc: 0.5193\n",
      "Epoch 727/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6857 - acc: 0.5420 - val_loss: 0.6927 - val_acc: 0.5251\n",
      "Epoch 728/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6863 - acc: 0.5389 - val_loss: 0.6928 - val_acc: 0.5242\n",
      "Epoch 729/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6818 - acc: 0.5488 - val_loss: 0.6928 - val_acc: 0.5232\n",
      "Epoch 730/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6879 - acc: 0.5332 - val_loss: 0.6929 - val_acc: 0.5251\n",
      "Epoch 731/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6853 - acc: 0.5518 - val_loss: 0.6930 - val_acc: 0.5280\n",
      "Epoch 732/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5438 - val_loss: 0.6927 - val_acc: 0.5261\n",
      "Epoch 733/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6878 - acc: 0.5290 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 734/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5472 - val_loss: 0.6928 - val_acc: 0.5280\n",
      "Epoch 735/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6831 - acc: 0.5515 - val_loss: 0.6928 - val_acc: 0.5222\n",
      "Epoch 736/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5420 - val_loss: 0.6927 - val_acc: 0.5290\n",
      "Epoch 737/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5478 - val_loss: 0.6929 - val_acc: 0.5261\n",
      "Epoch 738/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6831 - acc: 0.5523 - val_loss: 0.6928 - val_acc: 0.5232\n",
      "Epoch 739/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6872 - acc: 0.5435 - val_loss: 0.6928 - val_acc: 0.5261\n",
      "Epoch 740/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6848 - acc: 0.5449 - val_loss: 0.6928 - val_acc: 0.5271\n",
      "Epoch 741/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6860 - acc: 0.5463 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 742/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5401 - val_loss: 0.6925 - val_acc: 0.5290\n",
      "Epoch 743/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5375 - val_loss: 0.6927 - val_acc: 0.5261\n",
      "Epoch 744/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6880 - acc: 0.5375 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 745/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5465 - val_loss: 0.6927 - val_acc: 0.5271\n",
      "Epoch 746/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6846 - acc: 0.5465 - val_loss: 0.6928 - val_acc: 0.5261\n",
      "Epoch 747/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6844 - acc: 0.5472 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 748/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5447 - val_loss: 0.6927 - val_acc: 0.5261\n",
      "Epoch 749/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5447 - val_loss: 0.6927 - val_acc: 0.5242\n",
      "Epoch 750/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6842 - acc: 0.5476 - val_loss: 0.6927 - val_acc: 0.5193\n",
      "Epoch 751/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5478 - val_loss: 0.6926 - val_acc: 0.5290\n",
      "Epoch 752/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6849 - acc: 0.5504 - val_loss: 0.6925 - val_acc: 0.5261\n",
      "Epoch 753/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6850 - acc: 0.5462 - val_loss: 0.6925 - val_acc: 0.5251\n",
      "Epoch 754/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6837 - acc: 0.5521 - val_loss: 0.6925 - val_acc: 0.5261\n",
      "Epoch 755/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5389 - val_loss: 0.6924 - val_acc: 0.5232\n",
      "Epoch 756/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5394 - val_loss: 0.6924 - val_acc: 0.5271\n",
      "Epoch 757/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5507 - val_loss: 0.6924 - val_acc: 0.5261\n",
      "Epoch 758/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6818 - acc: 0.5523 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 759/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5394 - val_loss: 0.6923 - val_acc: 0.5251\n",
      "Epoch 760/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6843 - acc: 0.5483 - val_loss: 0.6924 - val_acc: 0.5290\n",
      "Epoch 761/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6833 - acc: 0.5480 - val_loss: 0.6925 - val_acc: 0.5300\n",
      "Epoch 762/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5423 - val_loss: 0.6925 - val_acc: 0.5222\n",
      "Epoch 763/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6859 - acc: 0.5394 - val_loss: 0.6924 - val_acc: 0.5271\n",
      "Epoch 764/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6871 - acc: 0.5381 - val_loss: 0.6923 - val_acc: 0.5300\n",
      "Epoch 765/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6866 - acc: 0.5431 - val_loss: 0.6924 - val_acc: 0.5271\n",
      "Epoch 766/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6828 - acc: 0.5460 - val_loss: 0.6925 - val_acc: 0.5271\n",
      "Epoch 767/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5488 - val_loss: 0.6924 - val_acc: 0.5271\n",
      "Epoch 768/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5518 - val_loss: 0.6924 - val_acc: 0.5261\n",
      "Epoch 769/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6847 - acc: 0.5428 - val_loss: 0.6926 - val_acc: 0.5251\n",
      "Epoch 770/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6843 - acc: 0.5489 - val_loss: 0.6925 - val_acc: 0.5300\n",
      "Epoch 771/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6868 - acc: 0.5404 - val_loss: 0.6925 - val_acc: 0.5319\n",
      "Epoch 772/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6849 - acc: 0.5478 - val_loss: 0.6924 - val_acc: 0.5348\n",
      "Epoch 773/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6873 - acc: 0.5393 - val_loss: 0.6925 - val_acc: 0.5319\n",
      "Epoch 774/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6859 - acc: 0.5467 - val_loss: 0.6926 - val_acc: 0.5329\n",
      "Epoch 775/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6864 - acc: 0.5518 - val_loss: 0.6926 - val_acc: 0.5300\n",
      "Epoch 776/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6859 - acc: 0.5468 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 777/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6836 - acc: 0.5521 - val_loss: 0.6925 - val_acc: 0.5290\n",
      "Epoch 778/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6870 - acc: 0.5422 - val_loss: 0.6925 - val_acc: 0.5261\n",
      "Epoch 779/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6854 - acc: 0.5393 - val_loss: 0.6925 - val_acc: 0.5280\n",
      "Epoch 780/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6857 - acc: 0.5502 - val_loss: 0.6925 - val_acc: 0.5251\n",
      "Epoch 781/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6839 - acc: 0.5478 - val_loss: 0.6926 - val_acc: 0.5329\n",
      "Epoch 782/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5525 - val_loss: 0.6926 - val_acc: 0.5338\n",
      "Epoch 783/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5455 - val_loss: 0.6924 - val_acc: 0.5261\n",
      "Epoch 784/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6846 - acc: 0.5509 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 785/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6839 - acc: 0.5510 - val_loss: 0.6926 - val_acc: 0.5261\n",
      "Epoch 786/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6864 - acc: 0.5401 - val_loss: 0.6926 - val_acc: 0.5300\n",
      "Epoch 787/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6881 - acc: 0.5290 - val_loss: 0.6924 - val_acc: 0.5261\n",
      "Epoch 788/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5542 - val_loss: 0.6924 - val_acc: 0.5319\n",
      "Epoch 789/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6837 - acc: 0.5549 - val_loss: 0.6924 - val_acc: 0.5338\n",
      "Epoch 790/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6849 - acc: 0.5473 - val_loss: 0.6924 - val_acc: 0.5242\n",
      "Epoch 791/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6835 - acc: 0.5480 - val_loss: 0.6923 - val_acc: 0.5329\n",
      "Epoch 792/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6843 - acc: 0.5470 - val_loss: 0.6922 - val_acc: 0.5338\n",
      "Epoch 793/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5546 - val_loss: 0.6924 - val_acc: 0.5261\n",
      "Epoch 794/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6834 - acc: 0.5489 - val_loss: 0.6923 - val_acc: 0.5290\n",
      "Epoch 795/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6857 - acc: 0.5394 - val_loss: 0.6925 - val_acc: 0.5280\n",
      "Epoch 796/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6832 - acc: 0.5499 - val_loss: 0.6923 - val_acc: 0.5300\n",
      "Epoch 797/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6824 - acc: 0.5488 - val_loss: 0.6924 - val_acc: 0.5309\n",
      "Epoch 798/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6829 - acc: 0.5504 - val_loss: 0.6923 - val_acc: 0.5290\n",
      "Epoch 799/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6854 - acc: 0.5489 - val_loss: 0.6922 - val_acc: 0.5309\n",
      "Epoch 800/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6823 - acc: 0.5521 - val_loss: 0.6924 - val_acc: 0.5309\n",
      "Epoch 801/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6851 - acc: 0.5463 - val_loss: 0.6923 - val_acc: 0.5358\n",
      "Epoch 802/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5483 - val_loss: 0.6923 - val_acc: 0.5329\n",
      "Epoch 803/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6870 - acc: 0.5407 - val_loss: 0.6924 - val_acc: 0.5338\n",
      "Epoch 804/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6827 - acc: 0.5465 - val_loss: 0.6925 - val_acc: 0.5309\n",
      "Epoch 805/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6848 - acc: 0.5467 - val_loss: 0.6924 - val_acc: 0.5338\n",
      "Epoch 806/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5478 - val_loss: 0.6924 - val_acc: 0.5426\n",
      "Epoch 807/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6857 - acc: 0.5359 - val_loss: 0.6924 - val_acc: 0.5397\n",
      "Epoch 808/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6814 - acc: 0.5645 - val_loss: 0.6925 - val_acc: 0.5319\n",
      "Epoch 809/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5491 - val_loss: 0.6923 - val_acc: 0.5309\n",
      "Epoch 810/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6844 - acc: 0.5436 - val_loss: 0.6926 - val_acc: 0.5290\n",
      "Epoch 811/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5481 - val_loss: 0.6926 - val_acc: 0.5319\n",
      "Epoch 812/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6827 - acc: 0.5496 - val_loss: 0.6924 - val_acc: 0.5280\n",
      "Epoch 813/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6841 - acc: 0.5451 - val_loss: 0.6926 - val_acc: 0.5319\n",
      "Epoch 814/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6846 - acc: 0.5455 - val_loss: 0.6925 - val_acc: 0.5300\n",
      "Epoch 815/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5552 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 816/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5436 - val_loss: 0.6925 - val_acc: 0.5309\n",
      "Epoch 817/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6831 - acc: 0.5452 - val_loss: 0.6924 - val_acc: 0.5261\n",
      "Epoch 818/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6845 - acc: 0.5489 - val_loss: 0.6924 - val_acc: 0.5309\n",
      "Epoch 819/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6843 - acc: 0.5480 - val_loss: 0.6925 - val_acc: 0.5368\n",
      "Epoch 820/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5492 - val_loss: 0.6926 - val_acc: 0.5358\n",
      "Epoch 821/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6845 - acc: 0.5465 - val_loss: 0.6925 - val_acc: 0.5348\n",
      "Epoch 822/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5383 - val_loss: 0.6925 - val_acc: 0.5261\n",
      "Epoch 823/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6827 - acc: 0.5505 - val_loss: 0.6926 - val_acc: 0.5338\n",
      "Epoch 824/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5581 - val_loss: 0.6925 - val_acc: 0.5309\n",
      "Epoch 825/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6843 - acc: 0.5513 - val_loss: 0.6927 - val_acc: 0.5309\n",
      "Epoch 826/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6847 - acc: 0.5594 - val_loss: 0.6926 - val_acc: 0.5348\n",
      "Epoch 827/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5375 - val_loss: 0.6926 - val_acc: 0.5338\n",
      "Epoch 828/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6825 - acc: 0.5475 - val_loss: 0.6927 - val_acc: 0.5377\n",
      "Epoch 829/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5473 - val_loss: 0.6926 - val_acc: 0.5377\n",
      "Epoch 830/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6823 - acc: 0.5512 - val_loss: 0.6925 - val_acc: 0.5348\n",
      "Epoch 831/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6875 - acc: 0.5373 - val_loss: 0.6925 - val_acc: 0.5338\n",
      "Epoch 832/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6832 - acc: 0.5460 - val_loss: 0.6927 - val_acc: 0.5329\n",
      "Epoch 833/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6818 - acc: 0.5480 - val_loss: 0.6926 - val_acc: 0.5338\n",
      "Epoch 834/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6815 - acc: 0.5562 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 835/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6837 - acc: 0.5517 - val_loss: 0.6925 - val_acc: 0.5319\n",
      "Epoch 836/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6836 - acc: 0.5502 - val_loss: 0.6925 - val_acc: 0.5348\n",
      "Epoch 837/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5566 - val_loss: 0.6925 - val_acc: 0.5290\n",
      "Epoch 838/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6861 - acc: 0.5465 - val_loss: 0.6925 - val_acc: 0.5290\n",
      "Epoch 839/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6833 - acc: 0.5515 - val_loss: 0.6925 - val_acc: 0.5309\n",
      "Epoch 840/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6832 - acc: 0.5523 - val_loss: 0.6926 - val_acc: 0.5329\n",
      "Epoch 841/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6832 - acc: 0.5534 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 842/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6854 - acc: 0.5430 - val_loss: 0.6927 - val_acc: 0.5358\n",
      "Epoch 843/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5513 - val_loss: 0.6926 - val_acc: 0.5338\n",
      "Epoch 844/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6832 - acc: 0.5473 - val_loss: 0.6928 - val_acc: 0.5309\n",
      "Epoch 845/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6822 - acc: 0.5621 - val_loss: 0.6926 - val_acc: 0.5290\n",
      "Epoch 846/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6822 - acc: 0.5570 - val_loss: 0.6926 - val_acc: 0.5290\n",
      "Epoch 847/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6832 - acc: 0.5629 - val_loss: 0.6927 - val_acc: 0.5319\n",
      "Epoch 848/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6815 - acc: 0.5549 - val_loss: 0.6928 - val_acc: 0.5261\n",
      "Epoch 849/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6833 - acc: 0.5509 - val_loss: 0.6928 - val_acc: 0.5290\n",
      "Epoch 850/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5418 - val_loss: 0.6927 - val_acc: 0.5290\n",
      "Epoch 851/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6878 - acc: 0.5409 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 852/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6857 - acc: 0.5435 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 853/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6830 - acc: 0.5526 - val_loss: 0.6926 - val_acc: 0.5319\n",
      "Epoch 854/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6837 - acc: 0.5500 - val_loss: 0.6926 - val_acc: 0.5300\n",
      "Epoch 855/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6835 - acc: 0.5549 - val_loss: 0.6926 - val_acc: 0.5280\n",
      "Epoch 856/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6810 - acc: 0.5621 - val_loss: 0.6927 - val_acc: 0.5251\n",
      "Epoch 857/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6833 - acc: 0.5497 - val_loss: 0.6927 - val_acc: 0.5261\n",
      "Epoch 858/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6844 - acc: 0.5513 - val_loss: 0.6926 - val_acc: 0.5251\n",
      "Epoch 859/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6859 - acc: 0.5468 - val_loss: 0.6927 - val_acc: 0.5300\n",
      "Epoch 860/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6821 - acc: 0.5536 - val_loss: 0.6929 - val_acc: 0.5232\n",
      "Epoch 861/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6839 - acc: 0.5483 - val_loss: 0.6931 - val_acc: 0.5222\n",
      "Epoch 862/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6819 - acc: 0.5499 - val_loss: 0.6930 - val_acc: 0.5222\n",
      "Epoch 863/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6812 - acc: 0.5587 - val_loss: 0.6928 - val_acc: 0.5222\n",
      "Epoch 864/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6813 - acc: 0.5584 - val_loss: 0.6929 - val_acc: 0.5242\n",
      "Epoch 865/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5523 - val_loss: 0.6928 - val_acc: 0.5242\n",
      "Epoch 866/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6826 - acc: 0.5539 - val_loss: 0.6928 - val_acc: 0.5242\n",
      "Epoch 867/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5483 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 868/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6844 - acc: 0.5475 - val_loss: 0.6928 - val_acc: 0.5242\n",
      "Epoch 869/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6829 - acc: 0.5488 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 870/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6819 - acc: 0.5552 - val_loss: 0.6926 - val_acc: 0.5309\n",
      "Epoch 871/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6819 - acc: 0.5451 - val_loss: 0.6927 - val_acc: 0.5290\n",
      "Epoch 872/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6851 - acc: 0.5470 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 873/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6813 - acc: 0.5612 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 874/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6830 - acc: 0.5473 - val_loss: 0.6929 - val_acc: 0.5290\n",
      "Epoch 875/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5513 - val_loss: 0.6928 - val_acc: 0.5193\n",
      "Epoch 876/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6822 - acc: 0.5446 - val_loss: 0.6930 - val_acc: 0.5213\n",
      "Epoch 877/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6828 - acc: 0.5447 - val_loss: 0.6927 - val_acc: 0.5290\n",
      "Epoch 878/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6827 - acc: 0.5591 - val_loss: 0.6929 - val_acc: 0.5193\n",
      "Epoch 879/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5459 - val_loss: 0.6928 - val_acc: 0.5232\n",
      "Epoch 880/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6847 - acc: 0.5550 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 881/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6852 - acc: 0.5414 - val_loss: 0.6929 - val_acc: 0.5232\n",
      "Epoch 882/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6810 - acc: 0.5639 - val_loss: 0.6931 - val_acc: 0.5242\n",
      "Epoch 883/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6830 - acc: 0.5518 - val_loss: 0.6929 - val_acc: 0.5222\n",
      "Epoch 884/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6833 - acc: 0.5406 - val_loss: 0.6930 - val_acc: 0.5232\n",
      "Epoch 885/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6817 - acc: 0.5581 - val_loss: 0.6930 - val_acc: 0.5261\n",
      "Epoch 886/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6812 - acc: 0.5497 - val_loss: 0.6929 - val_acc: 0.5222\n",
      "Epoch 887/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6838 - acc: 0.5436 - val_loss: 0.6927 - val_acc: 0.5213\n",
      "Epoch 888/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6846 - acc: 0.5433 - val_loss: 0.6927 - val_acc: 0.5242\n",
      "Epoch 889/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6826 - acc: 0.5546 - val_loss: 0.6926 - val_acc: 0.5251\n",
      "Epoch 890/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5549 - val_loss: 0.6928 - val_acc: 0.5164\n",
      "Epoch 891/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6831 - acc: 0.5529 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 892/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6840 - acc: 0.5520 - val_loss: 0.6927 - val_acc: 0.5203\n",
      "Epoch 893/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6831 - acc: 0.5473 - val_loss: 0.6929 - val_acc: 0.5261\n",
      "Epoch 894/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6822 - acc: 0.5547 - val_loss: 0.6928 - val_acc: 0.5213\n",
      "Epoch 895/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6854 - acc: 0.5435 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 896/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6837 - acc: 0.5504 - val_loss: 0.6927 - val_acc: 0.5242\n",
      "Epoch 897/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6845 - acc: 0.5463 - val_loss: 0.6929 - val_acc: 0.5222\n",
      "Epoch 898/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6791 - acc: 0.5558 - val_loss: 0.6928 - val_acc: 0.5213\n",
      "Epoch 899/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6802 - acc: 0.5550 - val_loss: 0.6927 - val_acc: 0.5184\n",
      "Epoch 900/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6801 - acc: 0.5568 - val_loss: 0.6928 - val_acc: 0.5213\n",
      "Epoch 901/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6851 - acc: 0.5412 - val_loss: 0.6926 - val_acc: 0.5174\n",
      "Epoch 902/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6816 - acc: 0.5562 - val_loss: 0.6926 - val_acc: 0.5251\n",
      "Epoch 903/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6793 - acc: 0.5560 - val_loss: 0.6927 - val_acc: 0.5213\n",
      "Epoch 904/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6823 - acc: 0.5544 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 905/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6822 - acc: 0.5581 - val_loss: 0.6926 - val_acc: 0.5251\n",
      "Epoch 906/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6839 - acc: 0.5433 - val_loss: 0.6927 - val_acc: 0.5203\n",
      "Epoch 907/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6855 - acc: 0.5512 - val_loss: 0.6926 - val_acc: 0.5203\n",
      "Epoch 908/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6803 - acc: 0.5550 - val_loss: 0.6925 - val_acc: 0.5271\n",
      "Epoch 909/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5550 - val_loss: 0.6928 - val_acc: 0.5184\n",
      "Epoch 910/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6819 - acc: 0.5575 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 911/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6825 - acc: 0.5613 - val_loss: 0.6925 - val_acc: 0.5242\n",
      "Epoch 912/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6831 - acc: 0.5546 - val_loss: 0.6926 - val_acc: 0.5213\n",
      "Epoch 913/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6815 - acc: 0.5599 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 914/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6809 - acc: 0.5504 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 915/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6830 - acc: 0.5515 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 916/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6847 - acc: 0.5499 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 917/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6813 - acc: 0.5534 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 918/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6805 - acc: 0.5603 - val_loss: 0.6924 - val_acc: 0.5251\n",
      "Epoch 919/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5565 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 920/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6842 - acc: 0.5492 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 921/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6833 - acc: 0.5494 - val_loss: 0.6925 - val_acc: 0.5232\n",
      "Epoch 922/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6819 - acc: 0.5587 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 923/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6830 - acc: 0.5507 - val_loss: 0.6927 - val_acc: 0.5213\n",
      "Epoch 924/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6809 - acc: 0.5539 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 925/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6835 - acc: 0.5465 - val_loss: 0.6927 - val_acc: 0.5213\n",
      "Epoch 926/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6814 - acc: 0.5702 - val_loss: 0.6926 - val_acc: 0.5222\n",
      "Epoch 927/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6790 - acc: 0.5660 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 928/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6832 - acc: 0.5570 - val_loss: 0.6927 - val_acc: 0.5203\n",
      "Epoch 929/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6842 - acc: 0.5565 - val_loss: 0.6927 - val_acc: 0.5193\n",
      "Epoch 930/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6790 - acc: 0.5565 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 931/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6834 - acc: 0.5555 - val_loss: 0.6926 - val_acc: 0.5203\n",
      "Epoch 932/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6809 - acc: 0.5608 - val_loss: 0.6926 - val_acc: 0.5242\n",
      "Epoch 933/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6838 - acc: 0.5533 - val_loss: 0.6926 - val_acc: 0.5232\n",
      "Epoch 934/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6825 - acc: 0.5586 - val_loss: 0.6928 - val_acc: 0.5222\n",
      "Epoch 935/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6820 - acc: 0.5492 - val_loss: 0.6928 - val_acc: 0.5184\n",
      "Epoch 936/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6815 - acc: 0.5576 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 937/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6812 - acc: 0.5570 - val_loss: 0.6928 - val_acc: 0.5174\n",
      "Epoch 938/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5480 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 939/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5587 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 940/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6815 - acc: 0.5581 - val_loss: 0.6929 - val_acc: 0.5213\n",
      "Epoch 941/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6799 - acc: 0.5536 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 942/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6822 - acc: 0.5488 - val_loss: 0.6927 - val_acc: 0.5242\n",
      "Epoch 943/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6801 - acc: 0.5586 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 944/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6821 - acc: 0.5489 - val_loss: 0.6927 - val_acc: 0.5242\n",
      "Epoch 945/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6806 - acc: 0.5526 - val_loss: 0.6926 - val_acc: 0.5271\n",
      "Epoch 946/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6827 - acc: 0.5570 - val_loss: 0.6927 - val_acc: 0.5203\n",
      "Epoch 947/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6833 - acc: 0.5483 - val_loss: 0.6926 - val_acc: 0.5193\n",
      "Epoch 948/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5583 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 949/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6813 - acc: 0.5589 - val_loss: 0.6928 - val_acc: 0.5271\n",
      "Epoch 950/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6834 - acc: 0.5592 - val_loss: 0.6927 - val_acc: 0.5222\n",
      "Epoch 951/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6823 - acc: 0.5467 - val_loss: 0.6929 - val_acc: 0.5251\n",
      "Epoch 952/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6846 - acc: 0.5502 - val_loss: 0.6928 - val_acc: 0.5280\n",
      "Epoch 953/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6803 - acc: 0.5587 - val_loss: 0.6927 - val_acc: 0.5300\n",
      "Epoch 954/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6834 - acc: 0.5536 - val_loss: 0.6929 - val_acc: 0.5309\n",
      "Epoch 955/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6811 - acc: 0.5584 - val_loss: 0.6926 - val_acc: 0.5280\n",
      "Epoch 956/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6824 - acc: 0.5428 - val_loss: 0.6928 - val_acc: 0.5290\n",
      "Epoch 957/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6822 - acc: 0.5473 - val_loss: 0.6926 - val_acc: 0.5280\n",
      "Epoch 958/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6799 - acc: 0.5668 - val_loss: 0.6926 - val_acc: 0.5290\n",
      "Epoch 959/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6809 - acc: 0.5634 - val_loss: 0.6926 - val_acc: 0.5280\n",
      "Epoch 960/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6818 - acc: 0.5554 - val_loss: 0.6926 - val_acc: 0.5300\n",
      "Epoch 961/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6813 - acc: 0.5631 - val_loss: 0.6927 - val_acc: 0.5300\n",
      "Epoch 962/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6788 - acc: 0.5541 - val_loss: 0.6927 - val_acc: 0.5309\n",
      "Epoch 963/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6816 - acc: 0.5591 - val_loss: 0.6927 - val_acc: 0.5280\n",
      "Epoch 964/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6820 - acc: 0.5612 - val_loss: 0.6927 - val_acc: 0.5251\n",
      "Epoch 965/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6812 - acc: 0.5544 - val_loss: 0.6928 - val_acc: 0.5271\n",
      "Epoch 966/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6802 - acc: 0.5591 - val_loss: 0.6929 - val_acc: 0.5290\n",
      "Epoch 967/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6828 - acc: 0.5589 - val_loss: 0.6929 - val_acc: 0.5338\n",
      "Epoch 968/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6837 - acc: 0.5523 - val_loss: 0.6931 - val_acc: 0.5319\n",
      "Epoch 969/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6789 - acc: 0.5599 - val_loss: 0.6929 - val_acc: 0.5338\n",
      "Epoch 970/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6816 - acc: 0.5629 - val_loss: 0.6931 - val_acc: 0.5290\n",
      "Epoch 971/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6802 - acc: 0.5603 - val_loss: 0.6933 - val_acc: 0.5309\n",
      "Epoch 972/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6793 - acc: 0.5687 - val_loss: 0.6930 - val_acc: 0.5251\n",
      "Epoch 973/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6793 - acc: 0.5610 - val_loss: 0.6930 - val_acc: 0.5271\n",
      "Epoch 974/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6808 - acc: 0.5550 - val_loss: 0.6932 - val_acc: 0.5271\n",
      "Epoch 975/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6817 - acc: 0.5557 - val_loss: 0.6933 - val_acc: 0.5222\n",
      "Epoch 976/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6813 - acc: 0.5523 - val_loss: 0.6931 - val_acc: 0.5251\n",
      "Epoch 977/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6849 - acc: 0.5491 - val_loss: 0.6931 - val_acc: 0.5300\n",
      "Epoch 978/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6791 - acc: 0.5626 - val_loss: 0.6930 - val_acc: 0.5242\n",
      "Epoch 979/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5529 - val_loss: 0.6928 - val_acc: 0.5271\n",
      "Epoch 980/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6804 - acc: 0.5647 - val_loss: 0.6931 - val_acc: 0.5271\n",
      "Epoch 981/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6825 - acc: 0.5478 - val_loss: 0.6930 - val_acc: 0.5271\n",
      "Epoch 982/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6836 - acc: 0.5451 - val_loss: 0.6931 - val_acc: 0.5232\n",
      "Epoch 983/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6796 - acc: 0.5628 - val_loss: 0.6928 - val_acc: 0.5251\n",
      "Epoch 984/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6834 - acc: 0.5539 - val_loss: 0.6932 - val_acc: 0.5290\n",
      "Epoch 985/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6789 - acc: 0.5620 - val_loss: 0.6933 - val_acc: 0.5251\n",
      "Epoch 986/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6813 - acc: 0.5650 - val_loss: 0.6931 - val_acc: 0.5242\n",
      "Epoch 987/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6836 - acc: 0.5478 - val_loss: 0.6932 - val_acc: 0.5261\n",
      "Epoch 988/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6822 - acc: 0.5586 - val_loss: 0.6931 - val_acc: 0.5309\n",
      "Epoch 989/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6826 - acc: 0.5566 - val_loss: 0.6933 - val_acc: 0.5280\n",
      "Epoch 990/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6791 - acc: 0.5515 - val_loss: 0.6931 - val_acc: 0.5261\n",
      "Epoch 991/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6812 - acc: 0.5523 - val_loss: 0.6931 - val_acc: 0.5251\n",
      "Epoch 992/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6781 - acc: 0.5629 - val_loss: 0.6933 - val_acc: 0.5222\n",
      "Epoch 993/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6809 - acc: 0.5610 - val_loss: 0.6934 - val_acc: 0.5232\n",
      "Epoch 994/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6812 - acc: 0.5571 - val_loss: 0.6932 - val_acc: 0.5271\n",
      "Epoch 995/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6801 - acc: 0.5676 - val_loss: 0.6929 - val_acc: 0.5280\n",
      "Epoch 996/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6812 - acc: 0.5536 - val_loss: 0.6930 - val_acc: 0.5232\n",
      "Epoch 997/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6792 - acc: 0.5554 - val_loss: 0.6931 - val_acc: 0.5309\n",
      "Epoch 998/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5563 - val_loss: 0.6930 - val_acc: 0.5309\n",
      "Epoch 999/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6769 - acc: 0.5636 - val_loss: 0.6931 - val_acc: 0.5290\n",
      "Epoch 1000/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6817 - acc: 0.5612 - val_loss: 0.6933 - val_acc: 0.5251\n",
      "Epoch 1001/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6799 - acc: 0.5526 - val_loss: 0.6933 - val_acc: 0.5290\n",
      "Epoch 1002/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6799 - acc: 0.5615 - val_loss: 0.6933 - val_acc: 0.5300\n",
      "Epoch 1003/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6806 - acc: 0.5578 - val_loss: 0.6932 - val_acc: 0.5280\n",
      "Epoch 1004/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5629 - val_loss: 0.6932 - val_acc: 0.5319\n",
      "Epoch 1005/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6808 - acc: 0.5557 - val_loss: 0.6930 - val_acc: 0.5309\n",
      "Epoch 1006/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6804 - acc: 0.5546 - val_loss: 0.6931 - val_acc: 0.5348\n",
      "Epoch 1007/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6785 - acc: 0.5600 - val_loss: 0.6931 - val_acc: 0.5271\n",
      "Epoch 1008/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6795 - acc: 0.5631 - val_loss: 0.6931 - val_acc: 0.5300\n",
      "Epoch 1009/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6789 - acc: 0.5589 - val_loss: 0.6930 - val_acc: 0.5300\n",
      "Epoch 1010/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6820 - acc: 0.5505 - val_loss: 0.6931 - val_acc: 0.5242\n",
      "Epoch 1011/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5644 - val_loss: 0.6932 - val_acc: 0.5271\n",
      "Epoch 1012/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6801 - acc: 0.5578 - val_loss: 0.6932 - val_acc: 0.5290\n",
      "Epoch 1013/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6810 - acc: 0.5583 - val_loss: 0.6931 - val_acc: 0.5290\n",
      "Epoch 1014/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6823 - acc: 0.5472 - val_loss: 0.6929 - val_acc: 0.5290\n",
      "Epoch 1015/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6805 - acc: 0.5557 - val_loss: 0.6931 - val_acc: 0.5290\n",
      "Epoch 1016/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6796 - acc: 0.5565 - val_loss: 0.6930 - val_acc: 0.5319\n",
      "Epoch 1017/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6765 - acc: 0.5645 - val_loss: 0.6931 - val_acc: 0.5213\n",
      "Epoch 1018/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6830 - acc: 0.5499 - val_loss: 0.6930 - val_acc: 0.5261\n",
      "Epoch 1019/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6809 - acc: 0.5552 - val_loss: 0.6930 - val_acc: 0.5280\n",
      "Epoch 1020/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6808 - acc: 0.5554 - val_loss: 0.6929 - val_acc: 0.5290\n",
      "Epoch 1021/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6829 - acc: 0.5546 - val_loss: 0.6929 - val_acc: 0.5290\n",
      "Epoch 1022/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6806 - acc: 0.5621 - val_loss: 0.6929 - val_acc: 0.5329\n",
      "Epoch 1023/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6803 - acc: 0.5541 - val_loss: 0.6929 - val_acc: 0.5358\n",
      "Epoch 1024/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6806 - acc: 0.5587 - val_loss: 0.6928 - val_acc: 0.5300\n",
      "Epoch 1025/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6804 - acc: 0.5631 - val_loss: 0.6928 - val_acc: 0.5290\n",
      "Epoch 1026/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6806 - acc: 0.5605 - val_loss: 0.6927 - val_acc: 0.5368\n",
      "Epoch 1027/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6802 - acc: 0.5581 - val_loss: 0.6927 - val_acc: 0.5319\n",
      "Epoch 1028/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6799 - acc: 0.5665 - val_loss: 0.6928 - val_acc: 0.5309\n",
      "Epoch 1029/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6775 - acc: 0.5645 - val_loss: 0.6927 - val_acc: 0.5319\n",
      "Epoch 1030/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6789 - acc: 0.5626 - val_loss: 0.6926 - val_acc: 0.5387\n",
      "Epoch 1031/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6763 - acc: 0.5731 - val_loss: 0.6928 - val_acc: 0.5348\n",
      "Epoch 1032/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6802 - acc: 0.5584 - val_loss: 0.6929 - val_acc: 0.5377\n",
      "Epoch 1033/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6768 - acc: 0.5724 - val_loss: 0.6930 - val_acc: 0.5348\n",
      "Epoch 1034/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6812 - acc: 0.5536 - val_loss: 0.6928 - val_acc: 0.5348\n",
      "Epoch 1035/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6799 - acc: 0.5663 - val_loss: 0.6928 - val_acc: 0.5358\n",
      "Epoch 1036/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6795 - acc: 0.5631 - val_loss: 0.6930 - val_acc: 0.5377\n",
      "Epoch 1037/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6799 - acc: 0.5682 - val_loss: 0.6928 - val_acc: 0.5348\n",
      "Epoch 1038/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6828 - acc: 0.5578 - val_loss: 0.6929 - val_acc: 0.5319\n",
      "Epoch 1039/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6796 - acc: 0.5583 - val_loss: 0.6929 - val_acc: 0.5329\n",
      "Epoch 1040/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6793 - acc: 0.5562 - val_loss: 0.6930 - val_acc: 0.5271\n",
      "Epoch 1041/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6824 - acc: 0.5509 - val_loss: 0.6929 - val_acc: 0.5329\n",
      "Epoch 1042/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6785 - acc: 0.5623 - val_loss: 0.6932 - val_acc: 0.5338\n",
      "Epoch 1043/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6814 - acc: 0.5624 - val_loss: 0.6933 - val_acc: 0.5329\n",
      "Epoch 1044/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6814 - acc: 0.5620 - val_loss: 0.6932 - val_acc: 0.5348\n",
      "Epoch 1045/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6802 - acc: 0.5600 - val_loss: 0.6933 - val_acc: 0.5329\n",
      "Epoch 1046/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6808 - acc: 0.5650 - val_loss: 0.6931 - val_acc: 0.5348\n",
      "Epoch 1047/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6766 - acc: 0.5731 - val_loss: 0.6933 - val_acc: 0.5290\n",
      "Epoch 1048/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6776 - acc: 0.5705 - val_loss: 0.6933 - val_acc: 0.5397\n",
      "Epoch 1049/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6811 - acc: 0.5579 - val_loss: 0.6934 - val_acc: 0.5348\n",
      "Epoch 1050/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6804 - acc: 0.5541 - val_loss: 0.6937 - val_acc: 0.5329\n",
      "Epoch 1051/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6831 - acc: 0.5570 - val_loss: 0.6933 - val_acc: 0.5377\n",
      "Epoch 1052/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6813 - acc: 0.5550 - val_loss: 0.6934 - val_acc: 0.5329\n",
      "Epoch 1053/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6790 - acc: 0.5612 - val_loss: 0.6936 - val_acc: 0.5319\n",
      "Epoch 1054/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6811 - acc: 0.5602 - val_loss: 0.6934 - val_acc: 0.5261\n",
      "Epoch 1055/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6756 - acc: 0.5695 - val_loss: 0.6936 - val_acc: 0.5309\n",
      "Epoch 1056/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6791 - acc: 0.5555 - val_loss: 0.6937 - val_acc: 0.5271\n",
      "Epoch 1057/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6811 - acc: 0.5678 - val_loss: 0.6937 - val_acc: 0.5319\n",
      "Epoch 1058/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6809 - acc: 0.5616 - val_loss: 0.6938 - val_acc: 0.5300\n",
      "Epoch 1059/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5613 - val_loss: 0.6939 - val_acc: 0.5300\n",
      "Epoch 1060/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6769 - acc: 0.5660 - val_loss: 0.6938 - val_acc: 0.5358\n",
      "Epoch 1061/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6804 - acc: 0.5671 - val_loss: 0.6938 - val_acc: 0.5319\n",
      "Epoch 1062/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6822 - acc: 0.5587 - val_loss: 0.6939 - val_acc: 0.5309\n",
      "Epoch 1063/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6818 - acc: 0.5512 - val_loss: 0.6939 - val_acc: 0.5300\n",
      "Epoch 1064/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6796 - acc: 0.5605 - val_loss: 0.6942 - val_acc: 0.5261\n",
      "Epoch 1065/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6773 - acc: 0.5599 - val_loss: 0.6941 - val_acc: 0.5300\n",
      "Epoch 1066/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6800 - acc: 0.5613 - val_loss: 0.6943 - val_acc: 0.5251\n",
      "Epoch 1067/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6807 - acc: 0.5523 - val_loss: 0.6944 - val_acc: 0.5261\n",
      "Epoch 1068/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6798 - acc: 0.5583 - val_loss: 0.6943 - val_acc: 0.5309\n",
      "Epoch 1069/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6782 - acc: 0.5636 - val_loss: 0.6943 - val_acc: 0.5203\n",
      "Epoch 1070/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6804 - acc: 0.5597 - val_loss: 0.6943 - val_acc: 0.5290\n",
      "Epoch 1071/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6752 - acc: 0.5713 - val_loss: 0.6944 - val_acc: 0.5203\n",
      "Epoch 1072/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6809 - acc: 0.5591 - val_loss: 0.6944 - val_acc: 0.5348\n",
      "Epoch 1073/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6784 - acc: 0.5563 - val_loss: 0.6944 - val_acc: 0.5203\n",
      "Epoch 1074/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6794 - acc: 0.5576 - val_loss: 0.6939 - val_acc: 0.5319\n",
      "Epoch 1075/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6814 - acc: 0.5616 - val_loss: 0.6940 - val_acc: 0.5309\n",
      "Epoch 1076/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6793 - acc: 0.5618 - val_loss: 0.6942 - val_acc: 0.5319\n",
      "Epoch 1077/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6794 - acc: 0.5579 - val_loss: 0.6942 - val_acc: 0.5271\n",
      "Epoch 1078/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6824 - acc: 0.5613 - val_loss: 0.6941 - val_acc: 0.5309\n",
      "Epoch 1079/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6809 - acc: 0.5558 - val_loss: 0.6942 - val_acc: 0.5271\n",
      "Epoch 1080/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6763 - acc: 0.5615 - val_loss: 0.6943 - val_acc: 0.5290\n",
      "Epoch 1081/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6818 - acc: 0.5515 - val_loss: 0.6943 - val_acc: 0.5280\n",
      "Epoch 1082/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6788 - acc: 0.5652 - val_loss: 0.6941 - val_acc: 0.5280\n",
      "Epoch 1083/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6780 - acc: 0.5640 - val_loss: 0.6942 - val_acc: 0.5300\n",
      "Epoch 1084/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6762 - acc: 0.5658 - val_loss: 0.6942 - val_acc: 0.5309\n",
      "Epoch 1085/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6799 - acc: 0.5599 - val_loss: 0.6942 - val_acc: 0.5329\n",
      "Epoch 1086/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6785 - acc: 0.5584 - val_loss: 0.6943 - val_acc: 0.5251\n",
      "Epoch 1087/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6800 - acc: 0.5570 - val_loss: 0.6944 - val_acc: 0.5290\n",
      "Epoch 1088/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6785 - acc: 0.5652 - val_loss: 0.6943 - val_acc: 0.5290\n",
      "Epoch 1089/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6789 - acc: 0.5554 - val_loss: 0.6941 - val_acc: 0.5319\n",
      "Epoch 1090/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6784 - acc: 0.5624 - val_loss: 0.6942 - val_acc: 0.5280\n",
      "Epoch 1091/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6797 - acc: 0.5629 - val_loss: 0.6942 - val_acc: 0.5338\n",
      "Epoch 1092/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6777 - acc: 0.5666 - val_loss: 0.6940 - val_acc: 0.5300\n",
      "Epoch 1093/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6807 - acc: 0.5603 - val_loss: 0.6939 - val_acc: 0.5309\n",
      "Epoch 1094/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6781 - acc: 0.5681 - val_loss: 0.6943 - val_acc: 0.5377\n",
      "Epoch 1095/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6786 - acc: 0.5615 - val_loss: 0.6943 - val_acc: 0.5319\n",
      "Epoch 1096/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6789 - acc: 0.5645 - val_loss: 0.6943 - val_acc: 0.5309\n",
      "Epoch 1097/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6787 - acc: 0.5626 - val_loss: 0.6943 - val_acc: 0.5280\n",
      "Epoch 1098/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6774 - acc: 0.5692 - val_loss: 0.6941 - val_acc: 0.5338\n",
      "Epoch 1099/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6797 - acc: 0.5639 - val_loss: 0.6943 - val_acc: 0.5329\n",
      "Epoch 1100/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6796 - acc: 0.5645 - val_loss: 0.6943 - val_acc: 0.5377\n",
      "Epoch 1101/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6785 - acc: 0.5620 - val_loss: 0.6941 - val_acc: 0.5387\n",
      "Epoch 1102/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6764 - acc: 0.5716 - val_loss: 0.6944 - val_acc: 0.5358\n",
      "Epoch 1103/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6780 - acc: 0.5674 - val_loss: 0.6944 - val_acc: 0.5368\n",
      "Epoch 1104/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6773 - acc: 0.5649 - val_loss: 0.6945 - val_acc: 0.5300\n",
      "Epoch 1105/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6795 - acc: 0.5649 - val_loss: 0.6945 - val_acc: 0.5368\n",
      "Epoch 1106/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5592 - val_loss: 0.6943 - val_acc: 0.5348\n",
      "Epoch 1107/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5636 - val_loss: 0.6943 - val_acc: 0.5309\n",
      "Epoch 1108/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6812 - acc: 0.5515 - val_loss: 0.6943 - val_acc: 0.5319\n",
      "Epoch 1109/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6790 - acc: 0.5583 - val_loss: 0.6943 - val_acc: 0.5309\n",
      "Epoch 1110/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6802 - acc: 0.5552 - val_loss: 0.6942 - val_acc: 0.5300\n",
      "Epoch 1111/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6815 - acc: 0.5595 - val_loss: 0.6942 - val_acc: 0.5358\n",
      "Epoch 1112/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6793 - acc: 0.5536 - val_loss: 0.6942 - val_acc: 0.5280\n",
      "Epoch 1113/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6779 - acc: 0.5789 - val_loss: 0.6945 - val_acc: 0.5271\n",
      "Epoch 1114/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6775 - acc: 0.5676 - val_loss: 0.6944 - val_acc: 0.5280\n",
      "Epoch 1115/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6790 - acc: 0.5621 - val_loss: 0.6944 - val_acc: 0.5290\n",
      "Epoch 1116/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6783 - acc: 0.5615 - val_loss: 0.6946 - val_acc: 0.5309\n",
      "Epoch 1117/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6780 - acc: 0.5666 - val_loss: 0.6944 - val_acc: 0.5290\n",
      "Epoch 1118/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6791 - acc: 0.5653 - val_loss: 0.6945 - val_acc: 0.5319\n",
      "Epoch 1119/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6790 - acc: 0.5605 - val_loss: 0.6946 - val_acc: 0.5319\n",
      "Epoch 1120/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5631 - val_loss: 0.6947 - val_acc: 0.5290\n",
      "Epoch 1121/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5607 - val_loss: 0.6948 - val_acc: 0.5300\n",
      "Epoch 1122/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6763 - acc: 0.5742 - val_loss: 0.6947 - val_acc: 0.5329\n",
      "Epoch 1123/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6786 - acc: 0.5647 - val_loss: 0.6947 - val_acc: 0.5290\n",
      "Epoch 1124/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6783 - acc: 0.5642 - val_loss: 0.6947 - val_acc: 0.5300\n",
      "Epoch 1125/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6770 - acc: 0.5668 - val_loss: 0.6949 - val_acc: 0.5358\n",
      "Epoch 1126/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6780 - acc: 0.5650 - val_loss: 0.6949 - val_acc: 0.5309\n",
      "Epoch 1127/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6778 - acc: 0.5644 - val_loss: 0.6949 - val_acc: 0.5319\n",
      "Epoch 1128/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6813 - acc: 0.5612 - val_loss: 0.6949 - val_acc: 0.5319\n",
      "Epoch 1129/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6776 - acc: 0.5565 - val_loss: 0.6948 - val_acc: 0.5358\n",
      "Epoch 1130/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6765 - acc: 0.5669 - val_loss: 0.6947 - val_acc: 0.5348\n",
      "Epoch 1131/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6794 - acc: 0.5531 - val_loss: 0.6947 - val_acc: 0.5338\n",
      "Epoch 1132/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6819 - acc: 0.5628 - val_loss: 0.6947 - val_acc: 0.5338\n",
      "Epoch 1133/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6775 - acc: 0.5655 - val_loss: 0.6948 - val_acc: 0.5329\n",
      "Epoch 1134/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6780 - acc: 0.5639 - val_loss: 0.6949 - val_acc: 0.5338\n",
      "Epoch 1135/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6776 - acc: 0.5623 - val_loss: 0.6949 - val_acc: 0.5348\n",
      "Epoch 1136/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6793 - acc: 0.5591 - val_loss: 0.6950 - val_acc: 0.5348\n",
      "Epoch 1137/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6788 - acc: 0.5589 - val_loss: 0.6950 - val_acc: 0.5329\n",
      "Epoch 1138/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6779 - acc: 0.5613 - val_loss: 0.6950 - val_acc: 0.5329\n",
      "Epoch 1139/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6798 - acc: 0.5583 - val_loss: 0.6949 - val_acc: 0.5309\n",
      "Epoch 1140/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6791 - acc: 0.5584 - val_loss: 0.6952 - val_acc: 0.5309\n",
      "Epoch 1141/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6794 - acc: 0.5698 - val_loss: 0.6951 - val_acc: 0.5329\n",
      "Epoch 1142/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6798 - acc: 0.5599 - val_loss: 0.6949 - val_acc: 0.5309\n",
      "Epoch 1143/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6784 - acc: 0.5649 - val_loss: 0.6947 - val_acc: 0.5338\n",
      "Epoch 1144/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6819 - acc: 0.5562 - val_loss: 0.6948 - val_acc: 0.5338\n",
      "Epoch 1145/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6819 - acc: 0.5521 - val_loss: 0.6948 - val_acc: 0.5329\n",
      "Epoch 1146/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6806 - acc: 0.5595 - val_loss: 0.6947 - val_acc: 0.5300\n",
      "Epoch 1147/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6793 - acc: 0.5586 - val_loss: 0.6947 - val_acc: 0.5377\n",
      "Epoch 1148/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6769 - acc: 0.5660 - val_loss: 0.6949 - val_acc: 0.5290\n",
      "Epoch 1149/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6790 - acc: 0.5697 - val_loss: 0.6947 - val_acc: 0.5368\n",
      "Epoch 1150/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6784 - acc: 0.5613 - val_loss: 0.6950 - val_acc: 0.5280\n",
      "Epoch 1151/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6781 - acc: 0.5650 - val_loss: 0.6947 - val_acc: 0.5329\n",
      "Epoch 1152/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6786 - acc: 0.5673 - val_loss: 0.6950 - val_acc: 0.5290\n",
      "Epoch 1153/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6806 - acc: 0.5650 - val_loss: 0.6948 - val_acc: 0.5290\n",
      "Epoch 1154/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6786 - acc: 0.5639 - val_loss: 0.6949 - val_acc: 0.5271\n",
      "Epoch 1155/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6796 - acc: 0.5650 - val_loss: 0.6948 - val_acc: 0.5251\n",
      "Epoch 1156/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6803 - acc: 0.5576 - val_loss: 0.6948 - val_acc: 0.5290\n",
      "Epoch 1157/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6775 - acc: 0.5655 - val_loss: 0.6948 - val_acc: 0.5290\n",
      "Epoch 1158/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6751 - acc: 0.5711 - val_loss: 0.6948 - val_acc: 0.5300\n",
      "Epoch 1159/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6788 - acc: 0.5616 - val_loss: 0.6950 - val_acc: 0.5348\n",
      "Epoch 1160/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6762 - acc: 0.5658 - val_loss: 0.6950 - val_acc: 0.5319\n",
      "Epoch 1161/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6768 - acc: 0.5642 - val_loss: 0.6953 - val_acc: 0.5251\n",
      "Epoch 1162/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6759 - acc: 0.5653 - val_loss: 0.6951 - val_acc: 0.5261\n",
      "Epoch 1163/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6739 - acc: 0.5743 - val_loss: 0.6952 - val_acc: 0.5280\n",
      "Epoch 1164/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6829 - acc: 0.5575 - val_loss: 0.6954 - val_acc: 0.5290\n",
      "Epoch 1165/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6787 - acc: 0.5594 - val_loss: 0.6954 - val_acc: 0.5300\n",
      "Epoch 1166/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6779 - acc: 0.5589 - val_loss: 0.6954 - val_acc: 0.5338\n",
      "Epoch 1167/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6771 - acc: 0.5644 - val_loss: 0.6956 - val_acc: 0.5251\n",
      "Epoch 1168/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6793 - acc: 0.5645 - val_loss: 0.6955 - val_acc: 0.5290\n",
      "Epoch 1169/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6786 - acc: 0.5640 - val_loss: 0.6957 - val_acc: 0.5290\n",
      "Epoch 1170/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6798 - acc: 0.5541 - val_loss: 0.6955 - val_acc: 0.5261\n",
      "Epoch 1171/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6790 - acc: 0.5615 - val_loss: 0.6956 - val_acc: 0.5251\n",
      "Epoch 1172/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6778 - acc: 0.5686 - val_loss: 0.6955 - val_acc: 0.5261\n",
      "Epoch 1173/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6764 - acc: 0.5681 - val_loss: 0.6955 - val_acc: 0.5280\n",
      "Epoch 1174/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6746 - acc: 0.5665 - val_loss: 0.6956 - val_acc: 0.5319\n",
      "Epoch 1175/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6778 - acc: 0.5655 - val_loss: 0.6956 - val_acc: 0.5309\n",
      "Epoch 1176/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6749 - acc: 0.5726 - val_loss: 0.6956 - val_acc: 0.5319\n",
      "Epoch 1177/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6775 - acc: 0.5657 - val_loss: 0.6953 - val_acc: 0.5358\n",
      "Epoch 1178/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6779 - acc: 0.5602 - val_loss: 0.6955 - val_acc: 0.5319\n",
      "Epoch 1179/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6793 - acc: 0.5655 - val_loss: 0.6955 - val_acc: 0.5319\n",
      "Epoch 1180/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6793 - acc: 0.5639 - val_loss: 0.6957 - val_acc: 0.5329\n",
      "Epoch 1181/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6759 - acc: 0.5640 - val_loss: 0.6955 - val_acc: 0.5358\n",
      "Epoch 1182/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6805 - acc: 0.5562 - val_loss: 0.6956 - val_acc: 0.5338\n",
      "Epoch 1183/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6779 - acc: 0.5698 - val_loss: 0.6957 - val_acc: 0.5338\n",
      "Epoch 1184/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6771 - acc: 0.5632 - val_loss: 0.6956 - val_acc: 0.5338\n",
      "Epoch 1185/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6792 - acc: 0.5589 - val_loss: 0.6957 - val_acc: 0.5309\n",
      "Epoch 1186/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6782 - acc: 0.5600 - val_loss: 0.6959 - val_acc: 0.5280\n",
      "Epoch 1187/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6800 - acc: 0.5603 - val_loss: 0.6958 - val_acc: 0.5300\n",
      "Epoch 1188/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6785 - acc: 0.5640 - val_loss: 0.6958 - val_acc: 0.5348\n",
      "Epoch 1189/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6756 - acc: 0.5705 - val_loss: 0.6957 - val_acc: 0.5368\n",
      "Epoch 1190/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6765 - acc: 0.5668 - val_loss: 0.6958 - val_acc: 0.5338\n",
      "Epoch 1191/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6814 - acc: 0.5517 - val_loss: 0.6958 - val_acc: 0.5309\n",
      "Epoch 1192/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6769 - acc: 0.5660 - val_loss: 0.6959 - val_acc: 0.5309\n",
      "Epoch 1193/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6783 - acc: 0.5647 - val_loss: 0.6958 - val_acc: 0.5338\n",
      "Epoch 1194/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6761 - acc: 0.5690 - val_loss: 0.6957 - val_acc: 0.5280\n",
      "Epoch 1195/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6778 - acc: 0.5681 - val_loss: 0.6958 - val_acc: 0.5338\n",
      "Epoch 1196/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6788 - acc: 0.5663 - val_loss: 0.6959 - val_acc: 0.5300\n",
      "Epoch 1197/1200\n",
      "6214/6214 [==============================] - 7s 1ms/step - loss: 0.6762 - acc: 0.5676 - val_loss: 0.6957 - val_acc: 0.5309\n",
      "Epoch 1198/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6760 - acc: 0.5689 - val_loss: 0.6958 - val_acc: 0.5280\n",
      "Epoch 1199/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6745 - acc: 0.5721 - val_loss: 0.6957 - val_acc: 0.5261\n",
      "Epoch 1200/1200\n",
      "6214/6214 [==============================] - 6s 1ms/step - loss: 0.6749 - acc: 0.5657 - val_loss: 0.6959 - val_acc: 0.5300\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = 1200,\n",
    "    validation_data = (x_test, y_test),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "\n",
    "plt.plot(accuracy, label = \"Train Accuracy\")\n",
    "plt.plot(val_accuracy, label = \"Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
